{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# /*==========================================================================================*\\\n",
    "# **                        _           _ _   _     _  _         _                            **\n",
    "# **                       | |__  _   _/ | |_| |__ | || |  _ __ | |__                         **\n",
    "# **                       | '_ \\| | | | | __| '_ \\| || |_| '_ \\| '_ \\                        **\n",
    "# **                       | |_) | |_| | | |_| | | |__   _| | | | | | |                       **\n",
    "# **                       |_.__/ \\__,_|_|\\__|_| |_|  |_| |_| |_|_| |_|                       **\n",
    "# \\*==========================================================================================*/\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "# Author: Bùi Tiến Thành - Tien-Thanh Bui (@bu1th4nh)\n",
    "# Title: playground.ipynb\n",
    "# Date: 2024/11/14 15:57:19\n",
    "# Description: \n",
    "# \n",
    "# (c) 2024 bu1th4nh. All rights reserved. \n",
    "# Written with dedication in the University of Central Florida, EPCOT and the Magic Kingdom.\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List, Dict, Any, Tuple, Union, Literal\n",
    "\n",
    "from train_test import prepare_trte_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_folder = 'ROSMAP'\n",
    "# view_list = [1,2]\n",
    "# num_epoch_pretrain = 500\n",
    "# num_epoch = 2500\n",
    "# lr_e_pretrain = 1e-3\n",
    "# lr_e = 5e-4\n",
    "# lr_c = 1e-3\n",
    "\n",
    "# if data_folder == 'ROSMAP':\n",
    "#     num_class = 2\n",
    "# if data_folder == 'BRCA':\n",
    "#     num_class = 5\n",
    "\n",
    "\n",
    "# data_tr_list, data_trte_list, trte_idx, labels_trte = prepare_trte_data(data_folder, view_list)\n",
    "\n",
    "# print(\"data_tr_list: \", type(data_tr_list))\n",
    "# print(\"data_trte_list: \", type(data_trte_list))\n",
    "# print(\"trte_idx: \", type(trte_idx))\n",
    "# print(\"labels_trte: \", type(labels_trte))\n",
    "\n",
    "\n",
    "# print()\n",
    "\n",
    "# print(\"data_tr_list: \", len(data_tr_list))\n",
    "# print(\"data_trte_list: \", len(data_trte_list))\n",
    "# print(\"labels_trte: \", len(labels_trte))\n",
    "\n",
    "\n",
    "# print()\n",
    "\n",
    "\n",
    "# print(\"data_tr_list: \", [Ariel.shape for Ariel in data_tr_list])\n",
    "# print(\"data_trte_list: \", [Ariel.shape for Ariel in data_trte_list])\n",
    "# print(\"labels_trte: \", labels_trte.shape)\n",
    "\n",
    "\n",
    "# print()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(trte_idx['tr'])\n",
    "# print(trte_idx['te'])\n",
    "\n",
    "\n",
    "# print()\n",
    "\n",
    "\n",
    "# print(\"data_tr_list: \", data_tr_list)\n",
    "# print(\"data_trte_list: \", data_trte_list)\n",
    "# print(\"trte_idx: \", trte_idx)\n",
    "# print(\"labels_trte: \", labels_trte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_BRCA = '/home/bu1th4nh/Datasets/BreastCancer/processed_crossOmics'\n",
    "test_info = pd.read_parquet(f'{PATH_BRCA}/testdata_classification.parquet')\n",
    "display(test_info.head())\n",
    "\n",
    "\n",
    "mRNA = pd.read_parquet(f'{PATH_BRCA}/mRNA.parquet')\n",
    "miRNA = pd.read_parquet(f'{PATH_BRCA}/miRNA.parquet')\n",
    "clinical = pd.read_parquet(f'{PATH_BRCA}/clinical.parquet')\n",
    "for label in clinical.columns:\n",
    "    clinical[label] = clinical[label].apply(lambda x: 1 if x == 'Positive' else 0)\n",
    "display(clinical.head().T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom___prepare_trte_data(\n",
    "    omic_layers: List[pd.DataFrame], \n",
    "    label_data_series: pd.Series,\n",
    "    tr_sample_list: List[str],\n",
    "    te_sample_list: List[str],\n",
    "    adj_parameter: int,\n",
    ") -> Tuple[\n",
    "    List[torch.Tensor], \n",
    "    List[torch.Tensor], \n",
    "    Dict[str, List[int]], \n",
    "    np.ndarray,\n",
    "    list,\n",
    "    int,\n",
    "    int,\n",
    "]:\n",
    "    # Set up num class and dim_he_list\n",
    "    num_class = len(label_data_series.unique())\n",
    "    dim_he_list = [layer.shape[0] for layer in omic_layers]\n",
    "\n",
    "\n",
    "    # Retrieve train/test labels\n",
    "    num_view = len(omic_layers)\n",
    "    labels_tr = label_data_series.loc[tr_sample_list].values.astype(int)\n",
    "    labels_te = label_data_series.loc[te_sample_list].values.astype(int)\n",
    "\n",
    "\n",
    "    # Retrieve train/test data\n",
    "    data_tr_list = []\n",
    "    data_te_list = []\n",
    "    for i in range(num_view):\n",
    "        data_tr_list.append(omic_layers[i].T.loc[tr_sample_list].values)\n",
    "        data_te_list.append(omic_layers[i].T.loc[te_sample_list].values)\n",
    "    \n",
    "\n",
    "    # Concatenate train/test data and create tensor\n",
    "    num_tr = data_tr_list[0].shape[0]\n",
    "    num_te = data_te_list[0].shape[0]\n",
    "    data_mat_list = []\n",
    "    for i in range(num_view):\n",
    "        data_mat_list.append(np.concatenate((data_tr_list[i], data_te_list[i]), axis=0))\n",
    "    \n",
    "    \n",
    "    \n",
    "    data_tensor_list = []\n",
    "    for i in range(len(data_mat_list)):\n",
    "        data_tensor_list.append(torch.FloatTensor(data_mat_list[i]))\n",
    "        if torch.cuda.is_available():\n",
    "            data_tensor_list[i] = data_tensor_list[i].cuda()\n",
    "    \n",
    "    \n",
    "    idx_dict = {}\n",
    "    idx_dict[\"tr\"] = list(range(num_tr))\n",
    "    idx_dict[\"te\"] = list(range(num_tr, (num_tr+num_te)))\n",
    "\n",
    "\n",
    "    data_train_list = []\n",
    "    data_all_list = []\n",
    "    for i in range(len(data_tensor_list)):\n",
    "        data_train_list.append(data_tensor_list[i][idx_dict[\"tr\"]].clone())\n",
    "        data_all_list.append(torch.cat((data_tensor_list[i][idx_dict[\"tr\"]].clone(),\n",
    "                                       data_tensor_list[i][idx_dict[\"te\"]].clone()),0))\n",
    "    labels = np.concatenate((labels_tr, labels_te))\n",
    "    \n",
    "    return data_train_list, data_all_list, idx_dict, labels, dim_he_list, num_class, adj_parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tr_list, data_trte_list, trte_idx, labels_trte, dim_he_list, num_class, adj_parameter = custom___prepare_trte_data(\n",
    "    omic_layers = [mRNA, miRNA],\n",
    "    label_data_series = clinical['ER'],\n",
    "    tr_sample_list = test_info.loc['Test000', 'ER_train'],\n",
    "    te_sample_list = test_info.loc['Test000', 'ER_test'],\n",
    "    adj_parameter = 0,\n",
    ")\n",
    "\n",
    "print('dim_he_list: ', dim_he_list)\n",
    "print('num_class: ', num_class)\n",
    "print('adj_parameter: ', adj_parameter)\n",
    "\n",
    "print()\n",
    "\n",
    "\n",
    "\n",
    "print(\"data_tr_list: \", type(data_tr_list))\n",
    "print(\"data_trte_list: \", type(data_trte_list))\n",
    "print(\"trte_idx: \", type(trte_idx))\n",
    "print(\"labels_trte: \", type(labels_trte))\n",
    "\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"data_tr_list: \", len(data_tr_list))\n",
    "print(\"data_trte_list: \", len(data_trte_list))\n",
    "print(\"labels_trte: \", len(labels_trte))\n",
    "\n",
    "\n",
    "print()\n",
    "\n",
    "\n",
    "print(\"data_tr_list: \", [Ariel.shape for Ariel in data_tr_list])\n",
    "print(\"data_trte_list: \", [Ariel.shape for Ariel in data_trte_list])\n",
    "print(\"labels_trte: \", labels_trte.shape)\n",
    "\n",
    "\n",
    "print()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(trte_idx['tr'])\n",
    "print(trte_idx['te'])\n",
    "\n",
    "\n",
    "print()\n",
    "\n",
    "\n",
    "print(\"data_tr_list: \", data_tr_list)\n",
    "print(\"data_trte_list: \", data_trte_list)\n",
    "print(\"trte_idx: \", trte_idx)\n",
    "print(\"labels_trte: \", labels_trte)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mlflow\n",
    "\n",
    "\n",
    "\n",
    "Ariel = pd.read_parquet(f\"MOGONET_AUC_result.parquet\")\n",
    "\n",
    "for label in [\"ER\", \"PR\", \"HER2\", \"TN\"]:\n",
    "    for cls_method in [\"SVM\", \"Random Forest\", \"Logistic Regression\", \"AdaBoost\"][:1]:\n",
    "        auc_values = Ariel[f\"{label}_{cls_method}_AUC\"].values\n",
    "        avg_auc = np.mean(auc_values)\n",
    "        std_auc = np.std(auc_values)\n",
    "        max_auc = np.max(auc_values)\n",
    "        min_auc = np.min(auc_values)\n",
    "        med_auc = np.median(auc_values)\n",
    "        \n",
    "        \n",
    "        # Logging\n",
    "        print(f\"{label} - {cls_method} - Mean AUC: {avg_auc}\")\n",
    "        print(f\"{label} - {cls_method} - Median AUC: {med_auc}\")\n",
    "        print(f\"{label} - {cls_method} - Std AUC: {std_auc}\")\n",
    "        print(f\"{label} - {cls_method} - Max AUC: {max_auc}\")\n",
    "        print(f\"{label} - {cls_method} - Min AUC: {min_auc}\")\n",
    "        print()\n",
    "\n",
    "        mlflow.log_metric(f\"{label} {cls_method} Mean AUC\", avg_auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Ariel': '1'}, {'Belle': '2'}, {'Cindy': '3'}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A1 = [{\"Ariel\": \"1\"}, {\"Belle\": \"2\"}, {\"Cindy\": \"3\"}]\n",
    "\n",
    "A2 = []\n",
    "for gg in A1:\n",
    "\n",
    "    A2.append(gg)\n",
    "    del gg\n",
    "\n",
    "\n",
    "A2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".mogonet.env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
