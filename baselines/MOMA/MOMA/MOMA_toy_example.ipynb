{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import  TensorDataset, DataLoader\n",
    "\n",
    "import os\n",
    "import copy\n",
    "import math\n",
    "\n",
    "from scipy.special import softmax\n",
    "from tqdm import tqdm\n",
    "import scipy.stats as ss\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_auc_score,accuracy_score,confusion_matrix,recall_score,precision_score,precision_recall_curve,f1_score,auc\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set_theme(color_codes=True)\n",
    "\n",
    "random_seed = 0\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed_all(random_seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)\n",
    "\n",
    "torch.cuda.set_device(2)\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='1'\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "skf2 = StratifiedKFold(n_splits=3, shuffle=True, random_state=0)\n",
    "\n",
    "\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=7, verbose=False, delta=0.0001, path='checkpoint.pt', trace_func=print):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "            path (str): Path for the checkpoint to be saved to.\n",
    "                            Default: 'checkpoint.pt'\n",
    "            trace_func (function): trace print function.\n",
    "                            Default: print            \n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.trace_func = trace_func\n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >self.patience:\n",
    "                self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        if self.verbose:\n",
    "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MOMA network for # of module = 16, 32, 64, 128\n",
    "-------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of Module = 16\n",
    "\n",
    "class mtlAttention(nn.Module):\n",
    "    def __init__(self, In_Nodes1,In_Nodes2, Modules):\n",
    "        super(mtlAttention, self).__init__()\n",
    "        self.Modules = Modules\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        self.task1_FC1_x = nn.Linear(In_Nodes1, Modules,bias=False)\n",
    "        self.task1_FC1_y = nn.Linear(In_Nodes1, Modules,bias=False)\n",
    "\n",
    "        self.task2_FC1_x = nn.Linear(In_Nodes2, Modules,bias=False)\n",
    "        self.task2_FC1_y = nn.Linear(In_Nodes2, Modules,bias=False)\n",
    "            \n",
    "        self.softmax  = nn.Softmax(dim=-1)\n",
    "        \n",
    "        self.task1_FC2 =nn.Sequential(nn.Linear(Modules*2, 16),nn.ReLU())\n",
    "        self.task2_FC2 = nn.Sequential(nn.Linear(Modules*2, 16),nn.ReLU())\n",
    "        \n",
    "        self.task1_FC3 = nn.Sequential(nn.Linear(16, 1), nn.Sigmoid())\n",
    "        self.task2_FC3 = nn.Sequential(nn.Linear(16, 1), nn.Sigmoid())\n",
    "\n",
    "    def forward_one(self,xg,xm):\n",
    "        xg_x = self.task1_FC1_x(xg)\n",
    "        xm_x = self.task2_FC1_x(xm)\n",
    "        xg_y = self.task1_FC1_y(xg)         \n",
    "        xm_y =self.task2_FC1_y(xm)\n",
    "\n",
    "        xg = torch.cat([xg_x.reshape(-1,1,self.Modules),xg_y.reshape(-1,1,self.Modules)], dim=1)\n",
    "        xm = torch.cat([xm_x.reshape(-1,1,self.Modules),xm_y.reshape(-1,1,self.Modules)], dim=1)\n",
    "        \n",
    "        norm  = torch.norm(xg, dim=1, keepdim=True)\n",
    "        xg = xg.div(norm)\n",
    "        \n",
    "        norm  = torch.norm(xm, dim=1, keepdim=True)\n",
    "        xm = xm.div(norm)\n",
    "        \n",
    "        energy =  torch.bmm(xg.reshape(-1,2,self.Modules).permute(0,2,1) ,xm.reshape(-1,2,self.Modules))\n",
    "        attention1 = self.softmax(energy.permute(0,2,1)).permute(0,2,1) \n",
    "        attention2 = self.softmax(energy).permute(0,2,1)\n",
    "        \n",
    "        xg_value = torch.bmm(xg,attention1) \n",
    "        xm_value = torch.bmm(xm,attention2)\n",
    "\n",
    "        xg = xg_value.view(-1,self.Modules*2)\n",
    "        xm =xm_value.view(-1,self.Modules*2)\n",
    "        \n",
    "        xg = self.task1_FC2(xg)\n",
    "        xm = self.task2_FC2(xm) \n",
    "        xg = self.task1_FC3(xg)\n",
    "        xm = self.task2_FC3(xm)\n",
    "        \n",
    "        return xg,xm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of Module = 32\n",
    "\n",
    "class mtlAttention(nn.Module):\n",
    "    def __init__(self, In_Nodes1,In_Nodes2, Modules):\n",
    "        super(mtlAttention, self).__init__()\n",
    "        self.Modules = Modules\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        self.task1_FC1_x = nn.Linear(In_Nodes1, Modules,bias=False)\n",
    "        self.task1_FC1_y = nn.Linear(In_Nodes1, Modules,bias=False)\n",
    "\n",
    "        self.task2_FC1_x = nn.Linear(In_Nodes2, Modules,bias=False)\n",
    "        self.task2_FC1_y = nn.Linear(In_Nodes2, Modules,bias=False)\n",
    "            \n",
    "        self.softmax  = nn.Softmax(dim=-1)\n",
    "        \n",
    "        self.task1_FC2 =nn.Sequential(nn.Linear(Modules*2, 32),nn.ReLU())\n",
    "        self.task2_FC2 = nn.Sequential(nn.Linear(Modules*2, 32),nn.ReLU())\n",
    "\n",
    "        self.task1_FC3 =nn.Sequential(nn.Linear(32, 16),nn.ReLU())\n",
    "        self.task2_FC3 = nn.Sequential(nn.Linear(32, 16),nn.ReLU())\n",
    "        \n",
    "        self.task1_FC4 = nn.Sequential(nn.Linear(16, 1), nn.Sigmoid())\n",
    "        self.task2_FC4 = nn.Sequential(nn.Linear(16, 1), nn.Sigmoid())\n",
    "\n",
    "    def forward_one(self,xg,xm):\n",
    "        xg_x = self.task1_FC1_x(xg)\n",
    "        xm_x = self.task2_FC1_x(xm)\n",
    "        xg_y = self.task1_FC1_y(xg)         \n",
    "        xm_y =self.task2_FC1_y(xm)\n",
    "\n",
    "        xg = torch.cat([xg_x.reshape(-1,1,self.Modules),xg_y.reshape(-1,1,self.Modules)], dim=1)\n",
    "        xm = torch.cat([xm_x.reshape(-1,1,self.Modules),xm_y.reshape(-1,1,self.Modules)], dim=1)\n",
    "        \n",
    "        norm  = torch.norm(xg, dim=1, keepdim=True)\n",
    "        xg = xg.div(norm)\n",
    "        \n",
    "        norm  = torch.norm(xm, dim=1, keepdim=True)\n",
    "        xm = xm.div(norm)\n",
    "        \n",
    "        energy =  torch.bmm(xg.reshape(-1,2,self.Modules).permute(0,2,1) ,xm.reshape(-1,2,self.Modules))\n",
    "        attention1 = self.softmax(energy.permute(0,2,1)).permute(0,2,1) \n",
    "        attention2 = self.softmax(energy).permute(0,2,1)\n",
    "        \n",
    "        xg_value = torch.bmm(xg,attention1) \n",
    "        xm_value = torch.bmm(xm,attention2)\n",
    "\n",
    "        xg = xg_value.view(-1,self.Modules*2)\n",
    "        xm =xm_value.view(-1,self.Modules*2)\n",
    "        \n",
    "        xg = self.task1_FC2(xg)\n",
    "        xm = self.task2_FC2(xm) \n",
    "        xg = self.task1_FC3(xg)\n",
    "        xm = self.task2_FC3(xm)\n",
    "        xg = self.task1_FC4(xg)\n",
    "        xm = self.task2_FC4(xm)\n",
    "        \n",
    "        return xg,xm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of Module = 64\n",
    "\n",
    "class mtlAttention(nn.Module):\n",
    "    def __init__(self, In_Nodes1,In_Nodes2, Modules):\n",
    "        super(mtlAttention, self).__init__()\n",
    "        self.Modules = Modules\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        self.task1_FC1_x = nn.Linear(In_Nodes1, Modules,bias=False)\n",
    "        self.task1_FC1_y = nn.Linear(In_Nodes1, Modules,bias=False)\n",
    "\n",
    "        self.task2_FC1_x = nn.Linear(In_Nodes2, Modules,bias=False)\n",
    "        self.task2_FC1_y = nn.Linear(In_Nodes2, Modules,bias=False)\n",
    "            \n",
    "        self.softmax  = nn.Softmax(dim=-1)\n",
    "        \n",
    "        self.task1_FC2 =nn.Sequential(nn.Linear(Modules*2, 64),nn.ReLU())\n",
    "        self.task2_FC2 = nn.Sequential(nn.Linear(Modules*2, 64),nn.ReLU())\n",
    "\n",
    "        self.task1_FC3 =nn.Sequential(nn.Linear(64, 32),nn.ReLU())\n",
    "        self.task2_FC3 = nn.Sequential(nn.Linear(64, 32),nn.ReLU())\n",
    "        \n",
    "        self.task1_FC4 =nn.Sequential(nn.Linear(32, 16),nn.ReLU())\n",
    "        self.task2_FC4 = nn.Sequential(nn.Linear(32, 16),nn.ReLU())\n",
    "        \n",
    "        self.task1_FC5 = nn.Sequential(nn.Linear(16, 1), nn.Sigmoid())\n",
    "        self.task2_FC5 = nn.Sequential(nn.Linear(16, 1), nn.Sigmoid())\n",
    "\n",
    "    def forward_one(self,xg,xm):\n",
    "        xg_x = self.task1_FC1_x(xg)\n",
    "        xm_x = self.task2_FC1_x(xm)\n",
    "        xg_y = self.task1_FC1_y(xg)         \n",
    "        xm_y =self.task2_FC1_y(xm)\n",
    "\n",
    "        xg = torch.cat([xg_x.reshape(-1,1,self.Modules),xg_y.reshape(-1,1,self.Modules)], dim=1)\n",
    "        xm = torch.cat([xm_x.reshape(-1,1,self.Modules),xm_y.reshape(-1,1,self.Modules)], dim=1)\n",
    "        \n",
    "        norm  = torch.norm(xg, dim=1, keepdim=True)\n",
    "        xg = xg.div(norm)\n",
    "        \n",
    "        norm  = torch.norm(xm, dim=1, keepdim=True)\n",
    "        xm = xm.div(norm)\n",
    "        \n",
    "        energy =  torch.bmm(xg.reshape(-1,2,self.Modules).permute(0,2,1) ,xm.reshape(-1,2,self.Modules))\n",
    "        attention1 = self.softmax(energy.permute(0,2,1)).permute(0,2,1) \n",
    "        attention2 = self.softmax(energy).permute(0,2,1)\n",
    "        \n",
    "        xg_value = torch.bmm(xg,attention1) \n",
    "        xm_value = torch.bmm(xm,attention2)\n",
    "\n",
    "        xg = xg_value.view(-1,self.Modules*2)\n",
    "        xm =xm_value.view(-1,self.Modules*2)\n",
    "        \n",
    "        xg = self.task1_FC2(xg)\n",
    "        xm = self.task2_FC2(xm) \n",
    "        xg = self.task1_FC3(xg)\n",
    "        xm = self.task2_FC3(xm)\n",
    "        xg = self.task1_FC4(xg)\n",
    "        xm = self.task2_FC4(xm)\n",
    "        xg = self.task1_FC5(xg)\n",
    "        xm = self.task2_FC5(xm)\n",
    "        \n",
    "        return xg,xm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of Module =128\n",
    "\n",
    "class mtlAttention(nn.Module):\n",
    "    def __init__(self, In_Nodes1,In_Nodes2, Modules):\n",
    "        super(mtlAttention, self).__init__()\n",
    "        self.Modules = Modules\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        self.task1_FC1_x = nn.Linear(In_Nodes1, Modules,bias=False)\n",
    "        self.task1_FC1_y = nn.Linear(In_Nodes1, Modules,bias=False)\n",
    "\n",
    "        self.task2_FC1_x = nn.Linear(In_Nodes2, Modules,bias=False)\n",
    "        self.task2_FC1_y = nn.Linear(In_Nodes2, Modules,bias=False)\n",
    "            \n",
    "        self.softmax  = nn.Softmax(dim=-1)\n",
    "        \n",
    "        self.task1_FC2 =nn.Sequential(nn.Linear(Modules*2, 128),nn.ReLU())\n",
    "        self.task2_FC2 = nn.Sequential(nn.Linear(Modules*2, 128),nn.ReLU())\n",
    "\n",
    "        self.task1_FC3 =nn.Sequential(nn.Linear(128, 64),nn.ReLU())\n",
    "        self.task2_FC3 = nn.Sequential(nn.Linear(128, 64),nn.ReLU())\n",
    "        \n",
    "        self.task1_FC4 =nn.Sequential(nn.Linear(64, 32),nn.ReLU())\n",
    "        self.task2_FC4 = nn.Sequential(nn.Linear(64, 32),nn.ReLU())\n",
    "        \n",
    "        self.task1_FC5 =nn.Sequential(nn.Linear(32, 16),nn.ReLU())\n",
    "        self.task2_FC5 = nn.Sequential(nn.Linear(32, 16),nn.ReLU())\n",
    "        \n",
    "        self.task1_FC6 = nn.Sequential(nn.Linear(16, 1), nn.Sigmoid())\n",
    "        self.task2_FC6 = nn.Sequential(nn.Linear(16, 1), nn.Sigmoid())\n",
    "\n",
    "    def forward_one(self,xg,xm):\n",
    "        xg_x = self.task1_FC1_x(xg)\n",
    "        xm_x = self.task2_FC1_x(xm)\n",
    "        xg_y = self.task1_FC1_y(xg)         \n",
    "        xm_y =self.task2_FC1_y(xm)\n",
    "\n",
    "        xg = torch.cat([xg_x.reshape(-1,1,self.Modules),xg_y.reshape(-1,1,self.Modules)], dim=1)\n",
    "        xm = torch.cat([xm_x.reshape(-1,1,self.Modules),xm_y.reshape(-1,1,self.Modules)], dim=1)\n",
    "        \n",
    "        norm  = torch.norm(xg, dim=1, keepdim=True)\n",
    "        xg = xg.div(norm)\n",
    "        \n",
    "        norm  = torch.norm(xm, dim=1, keepdim=True)\n",
    "        xm = xm.div(norm)\n",
    "        \n",
    "        energy =  torch.bmm(xg.reshape(-1,2,self.Modules).permute(0,2,1) ,xm.reshape(-1,2,self.Modules))\n",
    "        attention1 = self.softmax(energy.permute(0,2,1)).permute(0,2,1) \n",
    "        attention2 = self.softmax(energy).permute(0,2,1)\n",
    "        \n",
    "        xg_value = torch.bmm(xg,attention1) \n",
    "        xm_value = torch.bmm(xm,attention2)\n",
    "\n",
    "        xg = xg_value.view(-1,self.Modules*2)\n",
    "        xm =xm_value.view(-1,self.Modules*2)\n",
    "        \n",
    "        xg = self.task1_FC2(xg)\n",
    "        xm = self.task2_FC2(xm) \n",
    "        xg = self.task1_FC3(xg)\n",
    "        xm = self.task2_FC3(xm)\n",
    "        xg = self.task1_FC4(xg)\n",
    "        xm = self.task2_FC4(xm)\n",
    "        xg = self.task1_FC5(xg)\n",
    "        xm = self.task2_FC5(xm)\n",
    "        xg = self.task1_FC6(xg)\n",
    "        xm = self.task2_FC6(xm)\n",
    "        \n",
    "        return xg,xm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Toy Dataset load\n",
    "-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 200)\n",
      "(10000, 200)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NL</th>\n",
       "      <th>NL.1</th>\n",
       "      <th>NL.2</th>\n",
       "      <th>NL.3</th>\n",
       "      <th>NL.4</th>\n",
       "      <th>NL.5</th>\n",
       "      <th>NL.6</th>\n",
       "      <th>NL.7</th>\n",
       "      <th>NL.8</th>\n",
       "      <th>NL.9</th>\n",
       "      <th>...</th>\n",
       "      <th>AD.90</th>\n",
       "      <th>AD.91</th>\n",
       "      <th>AD.92</th>\n",
       "      <th>AD.93</th>\n",
       "      <th>AD.94</th>\n",
       "      <th>AD.95</th>\n",
       "      <th>AD.96</th>\n",
       "      <th>AD.97</th>\n",
       "      <th>AD.98</th>\n",
       "      <th>AD.99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.116170</td>\n",
       "      <td>0.484730</td>\n",
       "      <td>0.765863</td>\n",
       "      <td>0.021295</td>\n",
       "      <td>0.743884</td>\n",
       "      <td>0.706042</td>\n",
       "      <td>0.629633</td>\n",
       "      <td>0.581739</td>\n",
       "      <td>0.045158</td>\n",
       "      <td>0.012994</td>\n",
       "      <td>...</td>\n",
       "      <td>0.668131</td>\n",
       "      <td>0.877932</td>\n",
       "      <td>0.015292</td>\n",
       "      <td>0.241520</td>\n",
       "      <td>0.342196</td>\n",
       "      <td>0.546913</td>\n",
       "      <td>0.730232</td>\n",
       "      <td>0.531891</td>\n",
       "      <td>0.767411</td>\n",
       "      <td>0.552291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.210552</td>\n",
       "      <td>0.987877</td>\n",
       "      <td>0.846788</td>\n",
       "      <td>0.326554</td>\n",
       "      <td>0.274922</td>\n",
       "      <td>0.568553</td>\n",
       "      <td>0.649192</td>\n",
       "      <td>0.576963</td>\n",
       "      <td>0.140207</td>\n",
       "      <td>0.856503</td>\n",
       "      <td>...</td>\n",
       "      <td>0.677575</td>\n",
       "      <td>0.718003</td>\n",
       "      <td>0.877029</td>\n",
       "      <td>0.192422</td>\n",
       "      <td>0.653258</td>\n",
       "      <td>0.344119</td>\n",
       "      <td>0.149416</td>\n",
       "      <td>0.483794</td>\n",
       "      <td>0.090889</td>\n",
       "      <td>0.123862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.361542</td>\n",
       "      <td>0.733091</td>\n",
       "      <td>0.804966</td>\n",
       "      <td>0.708349</td>\n",
       "      <td>0.094293</td>\n",
       "      <td>0.332534</td>\n",
       "      <td>0.251071</td>\n",
       "      <td>0.420725</td>\n",
       "      <td>0.920967</td>\n",
       "      <td>0.667455</td>\n",
       "      <td>...</td>\n",
       "      <td>0.617281</td>\n",
       "      <td>0.939610</td>\n",
       "      <td>0.306295</td>\n",
       "      <td>0.226851</td>\n",
       "      <td>0.187190</td>\n",
       "      <td>0.445461</td>\n",
       "      <td>0.090538</td>\n",
       "      <td>0.075352</td>\n",
       "      <td>0.906092</td>\n",
       "      <td>0.348130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.903352</td>\n",
       "      <td>0.056806</td>\n",
       "      <td>0.517280</td>\n",
       "      <td>0.891021</td>\n",
       "      <td>0.445281</td>\n",
       "      <td>0.508423</td>\n",
       "      <td>0.557524</td>\n",
       "      <td>0.791278</td>\n",
       "      <td>0.223023</td>\n",
       "      <td>0.280712</td>\n",
       "      <td>...</td>\n",
       "      <td>0.061334</td>\n",
       "      <td>0.111495</td>\n",
       "      <td>0.128874</td>\n",
       "      <td>0.468554</td>\n",
       "      <td>0.233577</td>\n",
       "      <td>0.316638</td>\n",
       "      <td>0.886444</td>\n",
       "      <td>0.295920</td>\n",
       "      <td>0.729430</td>\n",
       "      <td>0.978662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.623518</td>\n",
       "      <td>0.757995</td>\n",
       "      <td>0.188339</td>\n",
       "      <td>0.755748</td>\n",
       "      <td>0.480622</td>\n",
       "      <td>0.484427</td>\n",
       "      <td>0.431002</td>\n",
       "      <td>0.540692</td>\n",
       "      <td>0.389817</td>\n",
       "      <td>0.964752</td>\n",
       "      <td>...</td>\n",
       "      <td>0.789149</td>\n",
       "      <td>0.479592</td>\n",
       "      <td>0.488383</td>\n",
       "      <td>0.376811</td>\n",
       "      <td>0.448327</td>\n",
       "      <td>0.018642</td>\n",
       "      <td>0.276544</td>\n",
       "      <td>0.093955</td>\n",
       "      <td>0.953279</td>\n",
       "      <td>0.274153</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         NL      NL.1      NL.2      NL.3      NL.4      NL.5      NL.6  \\\n",
       "1  0.116170  0.484730  0.765863  0.021295  0.743884  0.706042  0.629633   \n",
       "2  0.210552  0.987877  0.846788  0.326554  0.274922  0.568553  0.649192   \n",
       "3  0.361542  0.733091  0.804966  0.708349  0.094293  0.332534  0.251071   \n",
       "4  0.903352  0.056806  0.517280  0.891021  0.445281  0.508423  0.557524   \n",
       "5  0.623518  0.757995  0.188339  0.755748  0.480622  0.484427  0.431002   \n",
       "\n",
       "       NL.7      NL.8      NL.9  ...     AD.90     AD.91     AD.92     AD.93  \\\n",
       "1  0.581739  0.045158  0.012994  ...  0.668131  0.877932  0.015292  0.241520   \n",
       "2  0.576963  0.140207  0.856503  ...  0.677575  0.718003  0.877029  0.192422   \n",
       "3  0.420725  0.920967  0.667455  ...  0.617281  0.939610  0.306295  0.226851   \n",
       "4  0.791278  0.223023  0.280712  ...  0.061334  0.111495  0.128874  0.468554   \n",
       "5  0.540692  0.389817  0.964752  ...  0.789149  0.479592  0.488383  0.376811   \n",
       "\n",
       "      AD.94     AD.95     AD.96     AD.97     AD.98     AD.99  \n",
       "1  0.342196  0.546913  0.730232  0.531891  0.767411  0.552291  \n",
       "2  0.653258  0.344119  0.149416  0.483794  0.090889  0.123862  \n",
       "3  0.187190  0.445461  0.090538  0.075352  0.906092  0.348130  \n",
       "4  0.233577  0.316638  0.886444  0.295920  0.729430  0.978662  \n",
       "5  0.448327  0.018642  0.276544  0.093955  0.953279  0.274153  \n",
       "\n",
       "[5 rows x 200 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NL</th>\n",
       "      <th>NL.1</th>\n",
       "      <th>NL.2</th>\n",
       "      <th>NL.3</th>\n",
       "      <th>NL.4</th>\n",
       "      <th>NL.5</th>\n",
       "      <th>NL.6</th>\n",
       "      <th>NL.7</th>\n",
       "      <th>NL.8</th>\n",
       "      <th>NL.9</th>\n",
       "      <th>...</th>\n",
       "      <th>AD.90</th>\n",
       "      <th>AD.91</th>\n",
       "      <th>AD.92</th>\n",
       "      <th>AD.93</th>\n",
       "      <th>AD.94</th>\n",
       "      <th>AD.95</th>\n",
       "      <th>AD.96</th>\n",
       "      <th>AD.97</th>\n",
       "      <th>AD.98</th>\n",
       "      <th>AD.99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.890308</td>\n",
       "      <td>0.865166</td>\n",
       "      <td>0.478671</td>\n",
       "      <td>0.028633</td>\n",
       "      <td>0.170969</td>\n",
       "      <td>0.348456</td>\n",
       "      <td>0.203644</td>\n",
       "      <td>0.448393</td>\n",
       "      <td>0.211250</td>\n",
       "      <td>0.573695</td>\n",
       "      <td>...</td>\n",
       "      <td>0.253332</td>\n",
       "      <td>0.298901</td>\n",
       "      <td>0.125056</td>\n",
       "      <td>0.701550</td>\n",
       "      <td>0.125344</td>\n",
       "      <td>0.980233</td>\n",
       "      <td>0.099248</td>\n",
       "      <td>0.287076</td>\n",
       "      <td>0.952662</td>\n",
       "      <td>0.674368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.609219</td>\n",
       "      <td>0.284220</td>\n",
       "      <td>0.543996</td>\n",
       "      <td>0.917451</td>\n",
       "      <td>0.860072</td>\n",
       "      <td>0.415286</td>\n",
       "      <td>0.793022</td>\n",
       "      <td>0.615597</td>\n",
       "      <td>0.762030</td>\n",
       "      <td>0.621014</td>\n",
       "      <td>...</td>\n",
       "      <td>0.982748</td>\n",
       "      <td>0.444416</td>\n",
       "      <td>0.484416</td>\n",
       "      <td>0.396774</td>\n",
       "      <td>0.063317</td>\n",
       "      <td>0.741119</td>\n",
       "      <td>0.572365</td>\n",
       "      <td>0.358553</td>\n",
       "      <td>0.198042</td>\n",
       "      <td>0.155451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.308171</td>\n",
       "      <td>0.202429</td>\n",
       "      <td>0.359032</td>\n",
       "      <td>0.557569</td>\n",
       "      <td>0.314680</td>\n",
       "      <td>0.021956</td>\n",
       "      <td>0.568887</td>\n",
       "      <td>0.950882</td>\n",
       "      <td>0.492334</td>\n",
       "      <td>0.996104</td>\n",
       "      <td>...</td>\n",
       "      <td>0.126652</td>\n",
       "      <td>0.155060</td>\n",
       "      <td>0.822206</td>\n",
       "      <td>0.133126</td>\n",
       "      <td>0.289852</td>\n",
       "      <td>0.087857</td>\n",
       "      <td>0.462638</td>\n",
       "      <td>0.368656</td>\n",
       "      <td>0.916596</td>\n",
       "      <td>0.983870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.926951</td>\n",
       "      <td>0.189834</td>\n",
       "      <td>0.509452</td>\n",
       "      <td>0.945450</td>\n",
       "      <td>0.370921</td>\n",
       "      <td>0.731038</td>\n",
       "      <td>0.378588</td>\n",
       "      <td>0.448716</td>\n",
       "      <td>0.894263</td>\n",
       "      <td>0.144399</td>\n",
       "      <td>...</td>\n",
       "      <td>0.058988</td>\n",
       "      <td>0.195637</td>\n",
       "      <td>0.869381</td>\n",
       "      <td>0.433038</td>\n",
       "      <td>0.024058</td>\n",
       "      <td>0.571618</td>\n",
       "      <td>0.728784</td>\n",
       "      <td>0.613968</td>\n",
       "      <td>0.131461</td>\n",
       "      <td>0.103269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.010131</td>\n",
       "      <td>0.425635</td>\n",
       "      <td>0.543205</td>\n",
       "      <td>0.279344</td>\n",
       "      <td>0.880352</td>\n",
       "      <td>0.679096</td>\n",
       "      <td>0.982632</td>\n",
       "      <td>0.135022</td>\n",
       "      <td>0.937407</td>\n",
       "      <td>0.375202</td>\n",
       "      <td>...</td>\n",
       "      <td>0.548311</td>\n",
       "      <td>0.188440</td>\n",
       "      <td>0.388648</td>\n",
       "      <td>0.942772</td>\n",
       "      <td>0.807400</td>\n",
       "      <td>0.151173</td>\n",
       "      <td>0.600600</td>\n",
       "      <td>0.861974</td>\n",
       "      <td>0.397683</td>\n",
       "      <td>0.115345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         NL      NL.1      NL.2      NL.3      NL.4      NL.5      NL.6  \\\n",
       "1  0.890308  0.865166  0.478671  0.028633  0.170969  0.348456  0.203644   \n",
       "2  0.609219  0.284220  0.543996  0.917451  0.860072  0.415286  0.793022   \n",
       "3  0.308171  0.202429  0.359032  0.557569  0.314680  0.021956  0.568887   \n",
       "4  0.926951  0.189834  0.509452  0.945450  0.370921  0.731038  0.378588   \n",
       "5  0.010131  0.425635  0.543205  0.279344  0.880352  0.679096  0.982632   \n",
       "\n",
       "       NL.7      NL.8      NL.9  ...     AD.90     AD.91     AD.92     AD.93  \\\n",
       "1  0.448393  0.211250  0.573695  ...  0.253332  0.298901  0.125056  0.701550   \n",
       "2  0.615597  0.762030  0.621014  ...  0.982748  0.444416  0.484416  0.396774   \n",
       "3  0.950882  0.492334  0.996104  ...  0.126652  0.155060  0.822206  0.133126   \n",
       "4  0.448716  0.894263  0.144399  ...  0.058988  0.195637  0.869381  0.433038   \n",
       "5  0.135022  0.937407  0.375202  ...  0.548311  0.188440  0.388648  0.942772   \n",
       "\n",
       "      AD.94     AD.95     AD.96     AD.97     AD.98     AD.99  \n",
       "1  0.125344  0.980233  0.099248  0.287076  0.952662  0.674368  \n",
       "2  0.063317  0.741119  0.572365  0.358553  0.198042  0.155451  \n",
       "3  0.289852  0.087857  0.462638  0.368656  0.916596  0.983870  \n",
       "4  0.024058  0.571618  0.728784  0.613968  0.131461  0.103269  \n",
       "5  0.807400  0.151173  0.600600  0.861974  0.397683  0.115345  \n",
       "\n",
       "[5 rows x 200 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xg_data = pd.read_csv('../Example/toy_GE.csv',index_col=0)\n",
    "xm_data = pd.read_csv('../Example/toy_me.csv',index_col=0)\n",
    "\n",
    "print(xg_data.shape)\n",
    "print(xm_data.shape)\n",
    "\n",
    "display(xg_data.head())\n",
    "display(xm_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = pd.DataFrame(xg_data.columns)\n",
    "label.loc[label[0].str.contains('AD')] = 1\n",
    "label.loc[label[0]!=1] = 0 \n",
    "label = np.ravel(label, order='F').astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_data = xg_data.T\n",
    "xm_data = xm_data.T\n",
    "\n",
    "xg_data = xg_data.values\n",
    "xm_data = xm_data.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training\n",
    "----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2311809/57725633.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Xg_test = torch.tensor(Xg_test, dtype=torch.float32).cuda()\n",
      "/tmp/ipykernel_2311809/57725633.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Xm_test = torch.tensor(Xm_test, dtype=torch.float32).cuda()\n",
      "  0%|          | 6/500000 [00:00<8:28:09, 16.40it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/500000], Loss: 1.3967, BCE_task1; 0.6973, BCE_task2; 0.6994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2006/500000 [00:40<2:50:28, 48.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2000/500000], Loss: 0.9675, BCE_task1; 0.4661, BCE_task2; 0.5014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 4008/500000 [01:21<2:45:10, 50.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4000/500000], Loss: 0.3248, BCE_task1; 0.1844, BCE_task2; 0.1404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 6009/500000 [01:55<1:39:15, 82.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6000/500000], Loss: 0.0585, BCE_task1; 0.0350, BCE_task2; 0.0235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 8017/500000 [02:15<1:24:16, 97.30it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8000/500000], Loss: 0.0126, BCE_task1; 0.0071, BCE_task2; 0.0055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 10033/500000 [02:31<53:54, 151.50it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10000/500000], Loss: 0.0042, BCE_task1; 0.0022, BCE_task2; 0.0020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 10950/500000 [02:37<1:57:31, 69.36it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n",
      "--------------------------------------------------------------------------------------------------\n",
      "ACC_task1 0.525, ACC_task2 0.550\n",
      "F1_task1 0.095, F1_task2 0.182\n",
      "AUC_task1 0.713, AUC_task2 0.650\n",
      "time : 158.75290870666504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "j=0\n",
    "for train_index, test_index in skf.split(xg_data,label):\n",
    "    Xg_train, Xg_test = xg_data[train_index,:], xg_data[test_index,:]\n",
    "    Xm_train, Xm_test = xm_data[train_index,:], xm_data[test_index,:]\n",
    "    yg_train, yg_test = label[train_index], label[test_index]\n",
    "    j=j+1\n",
    "    if j==1: ### CV1 test\n",
    "        break\n",
    "\n",
    "earlyStoppingPatience = 100\n",
    "learningRate = 0.000005\n",
    "weightDecay = 0.001\n",
    "num_epochs = 500000 \n",
    "\n",
    "y_train = yg_train.flatten().astype(int)\n",
    "y_test = yg_test.flatten().astype(int)\n",
    "\n",
    "Xg = torch.tensor(Xg_train, dtype=torch.float32).cuda()\n",
    "Xm = torch.tensor(Xm_train, dtype=torch.float32).cuda()\n",
    "\n",
    "Xg_test = torch.tensor(Xg_test, dtype=torch.float32).cuda()\n",
    "Xm_test = torch.tensor(Xm_test, dtype=torch.float32).cuda()\n",
    "\n",
    "y = torch.tensor(y_train, dtype=torch.float32).cuda()\n",
    "\n",
    "ds = TensorDataset(Xg, Xm,y)\n",
    "loader  = DataLoader(ds, batch_size=y_train.shape[0],shuffle=True)\n",
    "\n",
    "Xg_test = torch.tensor(Xg_test, dtype=torch.float32).cuda()\n",
    "Xm_test = torch.tensor(Xm_test, dtype=torch.float32).cuda()\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "In_Nodes1 = Xg_train.shape[1] \n",
    "In_Nodes2 = Xm_train.shape[1]\n",
    "\n",
    "# mtlAttention(In_Nodes1,In_Nodes2, # of module)\n",
    "net = mtlAttention(In_Nodes1,In_Nodes2,32)\n",
    "net = net.to(device)\n",
    "early_stopping = EarlyStopping(patience=earlyStoppingPatience, verbose=False)\n",
    "optimizer = optim.Adam(net.parameters(), lr=learningRate, weight_decay=weightDecay)\n",
    "loss_fn = nn.BCELoss()\n",
    "\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    running_loss1 = 0.0\n",
    "    running_loss2 = 0.0\n",
    "    for i, data in enumerate(loader, 0):\n",
    "        xg,xm, y = data\n",
    "        output1,output2 = net.forward_one(xg,xm)\n",
    "        output1  = output1.squeeze()\n",
    "        output2  = output2.squeeze()\n",
    "        net.train()\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_fn(output1, y) + loss_fn(output2, y) \n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "        running_loss1 += loss_fn(output1,y.view(-1)).item()\n",
    "        running_loss2 += loss_fn(output2,y.view(-1)).item()\n",
    "\n",
    "\n",
    "    early_stopping(running_loss1+running_loss2, net)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping\")\n",
    "        print(\"--------------------------------------------------------------------------------------------------\")\n",
    "        break\n",
    "\n",
    "    if (epoch+1) % 2000 == 0 or epoch == 0:\n",
    "        if (epoch+1) % 2000 == 0 or epoch == 0:\n",
    "            print ('Epoch [{}/{}], Loss: {:.4f}, BCE_task1; {:.4f}, BCE_task2; {:.4f}'.format(epoch+1,num_epochs, running_loss1+running_loss2,running_loss1,running_loss2))\n",
    "\n",
    "### Test\n",
    "            \n",
    "test1,test2 = net.forward_one(Xg_test.clone().detach(),Xm_test.clone().detach())\n",
    "test1 = test1.cpu().detach().numpy()\n",
    "test2 = test2.cpu().detach().numpy()\n",
    "\n",
    "\n",
    "print (\"ACC_task1 %.3f, ACC_task2 %.3f\" %(accuracy_score(list(y_test),np.where(test1 > 0.5, 1, 0) ),accuracy_score(list(y_test),np.where(test2 > 0.5, 1, 0))))\n",
    "print (\"F1_task1 %.3f, F1_task2 %.3f\" %(f1_score(list(y_test),np.where(test1 > 0.5, 1, 0)),f1_score(list(y_test),np.where(test2 > 0.5, 1, 0))))\n",
    "print (\"AUC_task1 %.3f, AUC_task2 %.3f\" %(roc_auc_score(y_test.reshape(-1),test1),roc_auc_score(y_test.reshape(-1),test2)))\n",
    "print(\"time :\", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.7125), np.float64(0.6500000000000001))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test.reshape(-1),test1),roc_auc_score(y_test.reshape(-1),test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.12650125],\n",
       "       [0.19461219],\n",
       "       [0.3044043 ],\n",
       "       [0.08241447],\n",
       "       [0.0597868 ],\n",
       "       [0.09488948],\n",
       "       [0.16965076],\n",
       "       [0.02893816],\n",
       "       [0.18835683],\n",
       "       [0.0272963 ],\n",
       "       [0.19732077],\n",
       "       [0.04955429],\n",
       "       [0.13144045],\n",
       "       [0.19385155],\n",
       "       [0.16946684],\n",
       "       [0.06785356],\n",
       "       [0.3051527 ],\n",
       "       [0.19202611],\n",
       "       [0.20757379],\n",
       "       [0.22329745],\n",
       "       [0.13237321],\n",
       "       [0.34349763],\n",
       "       [0.24274045],\n",
       "       [0.3586874 ],\n",
       "       [0.01819521],\n",
       "       [0.15822978],\n",
       "       [0.16619699],\n",
       "       [0.05413078],\n",
       "       [0.5361367 ],\n",
       "       [0.16044882],\n",
       "       [0.1150272 ],\n",
       "       [0.24602355],\n",
       "       [0.41733226],\n",
       "       [0.24838267],\n",
       "       [0.12618327],\n",
       "       [0.13128294],\n",
       "       [0.44960058],\n",
       "       [0.30159596],\n",
       "       [0.66215366],\n",
       "       [0.11907807]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim = 32   # MOMA network for # of module \n",
    "\n",
    "y_all = np.concatenate((y_train,y_test+2))\n",
    "y_all \n",
    "# 0 : NL Train\n",
    "# 1 : AD Train \n",
    "# 2 : NL Test\n",
    "# 3 : AD Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The analysis can vary depending on the purpose of the experiment.  \n",
    "#### Below, we get importance score for Train AD samples.     \"if y_all[i]==1\" \n",
    "\n",
    "#### If you want to find it for the entire sample, just subtract the if, or if you want to find it for the test NL, use \"if y_all[i]==2\" \n",
    "####    See comment \"change this point\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate similarity score\n",
    "---------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2311809/59325228.py:30: RuntimeWarning: '<' not supported between instances of 'tuple' and 'int', sort order is undefined for incomparable objects.\n",
      "  sum_all = sum_all.add(atte2, fill_value=0)\n",
      "/tmp/ipykernel_2311809/59325228.py:30: RuntimeWarning: '<' not supported between instances of 'tuple' and 'int', sort order is undefined for incomparable objects.\n",
      "  sum_all = sum_all.add(atte2, fill_value=0)\n",
      "/tmp/ipykernel_2311809/59325228.py:30: RuntimeWarning: '<' not supported between instances of 'tuple' and 'int', sort order is undefined for incomparable objects.\n",
      "  sum_all = sum_all.add(atte2, fill_value=0)\n",
      "/tmp/ipykernel_2311809/59325228.py:30: RuntimeWarning: '<' not supported between instances of 'tuple' and 'int', sort order is undefined for incomparable objects.\n",
      "  sum_all = sum_all.add(atte2, fill_value=0)\n",
      "/tmp/ipykernel_2311809/59325228.py:30: RuntimeWarning: '<' not supported between instances of 'tuple' and 'int', sort order is undefined for incomparable objects.\n",
      "  sum_all = sum_all.add(atte2, fill_value=0)\n",
      "/tmp/ipykernel_2311809/59325228.py:30: RuntimeWarning: '<' not supported between instances of 'tuple' and 'int', sort order is undefined for incomparable objects.\n",
      "  sum_all = sum_all.add(atte2, fill_value=0)\n",
      "/tmp/ipykernel_2311809/59325228.py:30: RuntimeWarning: '<' not supported between instances of 'tuple' and 'int', sort order is undefined for incomparable objects.\n",
      "  sum_all = sum_all.add(atte2, fill_value=0)\n",
      "/tmp/ipykernel_2311809/59325228.py:30: RuntimeWarning: '<' not supported between instances of 'tuple' and 'int', sort order is undefined for incomparable objects.\n",
      "  sum_all = sum_all.add(atte2, fill_value=0)\n",
      "/tmp/ipykernel_2311809/59325228.py:30: RuntimeWarning: '<' not supported between instances of 'tuple' and 'int', sort order is undefined for incomparable objects.\n",
      "  sum_all = sum_all.add(atte2, fill_value=0)\n",
      "/tmp/ipykernel_2311809/59325228.py:30: RuntimeWarning: '<' not supported between instances of 'tuple' and 'int', sort order is undefined for incomparable objects.\n",
      "  sum_all = sum_all.add(atte2, fill_value=0)\n",
      "/tmp/ipykernel_2311809/59325228.py:30: RuntimeWarning: '<' not supported between instances of 'tuple' and 'int', sort order is undefined for incomparable objects.\n",
      "  sum_all = sum_all.add(atte2, fill_value=0)\n",
      "/tmp/ipykernel_2311809/59325228.py:30: RuntimeWarning: '<' not supported between instances of 'tuple' and 'int', sort order is undefined for incomparable objects.\n",
      "  sum_all = sum_all.add(atte2, fill_value=0)\n",
      "/tmp/ipykernel_2311809/59325228.py:30: RuntimeWarning: '<' not supported between instances of 'tuple' and 'int', sort order is undefined for incomparable objects.\n",
      "  sum_all = sum_all.add(atte2, fill_value=0)\n",
      "/tmp/ipykernel_2311809/59325228.py:30: RuntimeWarning: '<' not supported between instances of 'tuple' and 'int', sort order is undefined for incomparable objects.\n",
      "  sum_all = sum_all.add(atte2, fill_value=0)\n",
      "/tmp/ipykernel_2311809/59325228.py:30: RuntimeWarning: '<' not supported between instances of 'tuple' and 'int', sort order is undefined for incomparable objects.\n",
      "  sum_all = sum_all.add(atte2, fill_value=0)\n",
      "/tmp/ipykernel_2311809/59325228.py:30: RuntimeWarning: '<' not supported between instances of 'tuple' and 'int', sort order is undefined for incomparable objects.\n",
      "  sum_all = sum_all.add(atte2, fill_value=0)\n",
      "/tmp/ipykernel_2311809/59325228.py:30: RuntimeWarning: '<' not supported between instances of 'tuple' and 'int', sort order is undefined for incomparable objects.\n",
      "  sum_all = sum_all.add(atte2, fill_value=0)\n",
      "/tmp/ipykernel_2311809/59325228.py:30: RuntimeWarning: '<' not supported between instances of 'tuple' and 'int', sort order is undefined for incomparable objects.\n",
      "  sum_all = sum_all.add(atte2, fill_value=0)\n",
      "/tmp/ipykernel_2311809/59325228.py:30: RuntimeWarning: '<' not supported between instances of 'tuple' and 'int', sort order is undefined for incomparable objects.\n",
      "  sum_all = sum_all.add(atte2, fill_value=0)\n",
      "/tmp/ipykernel_2311809/59325228.py:30: RuntimeWarning: '<' not supported between instances of 'tuple' and 'int', sort order is undefined for incomparable objects.\n",
      "  sum_all = sum_all.add(atte2, fill_value=0)\n",
      "/tmp/ipykernel_2311809/59325228.py:30: RuntimeWarning: '<' not supported between instances of 'tuple' and 'int', sort order is undefined for incomparable objects.\n",
      "  sum_all = sum_all.add(atte2, fill_value=0)\n",
      "/tmp/ipykernel_2311809/59325228.py:30: RuntimeWarning: '<' not supported between instances of 'tuple' and 'int', sort order is undefined for incomparable objects.\n",
      "  sum_all = sum_all.add(atte2, fill_value=0)\n",
      "/tmp/ipykernel_2311809/59325228.py:30: RuntimeWarning: '<' not supported between instances of 'tuple' and 'int', sort order is undefined for incomparable objects.\n",
      "  sum_all = sum_all.add(atte2, fill_value=0)\n",
      "/tmp/ipykernel_2311809/59325228.py:30: RuntimeWarning: '<' not supported between instances of 'tuple' and 'int', sort order is undefined for incomparable objects.\n",
      "  sum_all = sum_all.add(atte2, fill_value=0)\n",
      "/tmp/ipykernel_2311809/59325228.py:30: RuntimeWarning: '<' not supported between instances of 'tuple' and 'int', sort order is undefined for incomparable objects.\n",
      "  sum_all = sum_all.add(atte2, fill_value=0)\n",
      "/tmp/ipykernel_2311809/59325228.py:30: RuntimeWarning: '<' not supported between instances of 'tuple' and 'int', sort order is undefined for incomparable objects.\n",
      "  sum_all = sum_all.add(atte2, fill_value=0)\n",
      "/tmp/ipykernel_2311809/59325228.py:30: RuntimeWarning: '<' not supported between instances of 'tuple' and 'int', sort order is undefined for incomparable objects.\n",
      "  sum_all = sum_all.add(atte2, fill_value=0)\n",
      "/tmp/ipykernel_2311809/59325228.py:30: RuntimeWarning: '<' not supported between instances of 'tuple' and 'int', sort order is undefined for incomparable objects.\n",
      "  sum_all = sum_all.add(atte2, fill_value=0)\n",
      "/tmp/ipykernel_2311809/59325228.py:30: RuntimeWarning: '<' not supported between instances of 'tuple' and 'int', sort order is undefined for incomparable objects.\n",
      "  sum_all = sum_all.add(atte2, fill_value=0)\n",
      "/tmp/ipykernel_2311809/59325228.py:30: RuntimeWarning: '<' not supported between instances of 'tuple' and 'int', sort order is undefined for incomparable objects.\n",
      "  sum_all = sum_all.add(atte2, fill_value=0)\n",
      "/tmp/ipykernel_2311809/59325228.py:30: RuntimeWarning: '<' not supported between instances of 'tuple' and 'int', sort order is undefined for incomparable objects.\n",
      "  sum_all = sum_all.add(atte2, fill_value=0)\n",
      "/tmp/ipykernel_2311809/59325228.py:30: RuntimeWarning: '<' not supported between instances of 'tuple' and 'int', sort order is undefined for incomparable objects.\n",
      "  sum_all = sum_all.add(atte2, fill_value=0)\n",
      "/tmp/ipykernel_2311809/59325228.py:30: RuntimeWarning: '<' not supported between instances of 'tuple' and 'int', sort order is undefined for incomparable objects.\n",
      "  sum_all = sum_all.add(atte2, fill_value=0)\n",
      "/tmp/ipykernel_2311809/59325228.py:30: RuntimeWarning: '<' not supported between instances of 'tuple' and 'int', sort order is undefined for incomparable objects.\n",
      "  sum_all = sum_all.add(atte2, fill_value=0)\n",
      "/tmp/ipykernel_2311809/59325228.py:30: RuntimeWarning: '<' not supported between instances of 'tuple' and 'int', sort order is undefined for incomparable objects.\n",
      "  sum_all = sum_all.add(atte2, fill_value=0)\n",
      "/tmp/ipykernel_2311809/59325228.py:30: RuntimeWarning: '<' not supported between instances of 'tuple' and 'int', sort order is undefined for incomparable objects.\n",
      "  sum_all = sum_all.add(atte2, fill_value=0)\n",
      "/tmp/ipykernel_2311809/59325228.py:30: RuntimeWarning: '<' not supported between instances of 'tuple' and 'int', sort order is undefined for incomparable objects.\n",
      "  sum_all = sum_all.add(atte2, fill_value=0)\n",
      "/tmp/ipykernel_2311809/59325228.py:30: RuntimeWarning: '<' not supported between instances of 'tuple' and 'int', sort order is undefined for incomparable objects.\n",
      "  sum_all = sum_all.add(atte2, fill_value=0)\n",
      "/tmp/ipykernel_2311809/59325228.py:30: RuntimeWarning: '<' not supported between instances of 'tuple' and 'int', sort order is undefined for incomparable objects.\n",
      "  sum_all = sum_all.add(atte2, fill_value=0)\n",
      "/tmp/ipykernel_2311809/59325228.py:30: RuntimeWarning: '<' not supported between instances of 'tuple' and 'int', sort order is undefined for incomparable objects.\n",
      "  sum_all = sum_all.add(atte2, fill_value=0)\n",
      "/tmp/ipykernel_2311809/59325228.py:30: RuntimeWarning: '<' not supported between instances of 'tuple' and 'int', sort order is undefined for incomparable objects.\n",
      "  sum_all = sum_all.add(atte2, fill_value=0)\n",
      "/tmp/ipykernel_2311809/59325228.py:30: RuntimeWarning: '<' not supported between instances of 'tuple' and 'int', sort order is undefined for incomparable objects.\n",
      "  sum_all = sum_all.add(atte2, fill_value=0)\n",
      "/tmp/ipykernel_2311809/59325228.py:30: RuntimeWarning: '<' not supported between instances of 'tuple' and 'int', sort order is undefined for incomparable objects.\n",
      "  sum_all = sum_all.add(atte2, fill_value=0)\n",
      "/tmp/ipykernel_2311809/59325228.py:30: RuntimeWarning: '<' not supported between instances of 'tuple' and 'int', sort order is undefined for incomparable objects.\n",
      "  sum_all = sum_all.add(atte2, fill_value=0)\n",
      "/tmp/ipykernel_2311809/59325228.py:30: RuntimeWarning: '<' not supported between instances of 'tuple' and 'int', sort order is undefined for incomparable objects.\n",
      "  sum_all = sum_all.add(atte2, fill_value=0)\n",
      "/tmp/ipykernel_2311809/59325228.py:30: RuntimeWarning: '<' not supported between instances of 'tuple' and 'int', sort order is undefined for incomparable objects.\n",
      "  sum_all = sum_all.add(atte2, fill_value=0)\n",
      "/tmp/ipykernel_2311809/59325228.py:30: RuntimeWarning: '<' not supported between instances of 'tuple' and 'int', sort order is undefined for incomparable objects.\n",
      "  sum_all = sum_all.add(atte2, fill_value=0)\n",
      "/tmp/ipykernel_2311809/59325228.py:30: RuntimeWarning: '<' not supported between instances of 'tuple' and 'int', sort order is undefined for incomparable objects.\n",
      "  sum_all = sum_all.add(atte2, fill_value=0)\n",
      "/tmp/ipykernel_2311809/59325228.py:30: RuntimeWarning: '<' not supported between instances of 'tuple' and 'int', sort order is undefined for incomparable objects.\n",
      "  sum_all = sum_all.add(atte2, fill_value=0)\n",
      "/tmp/ipykernel_2311809/59325228.py:30: RuntimeWarning: '<' not supported between instances of 'tuple' and 'int', sort order is undefined for incomparable objects.\n",
      "  sum_all = sum_all.add(atte2, fill_value=0)\n",
      "/tmp/ipykernel_2311809/59325228.py:30: RuntimeWarning: '<' not supported between instances of 'tuple' and 'int', sort order is undefined for incomparable objects.\n",
      "  sum_all = sum_all.add(atte2, fill_value=0)\n",
      "/tmp/ipykernel_2311809/59325228.py:30: RuntimeWarning: '<' not supported between instances of 'tuple' and 'int', sort order is undefined for incomparable objects.\n",
      "  sum_all = sum_all.add(atte2, fill_value=0)\n",
      "/tmp/ipykernel_2311809/59325228.py:30: RuntimeWarning: '<' not supported between instances of 'tuple' and 'int', sort order is undefined for incomparable objects.\n",
      "  sum_all = sum_all.add(atte2, fill_value=0)\n",
      "/tmp/ipykernel_2311809/59325228.py:30: RuntimeWarning: '<' not supported between instances of 'tuple' and 'int', sort order is undefined for incomparable objects.\n",
      "  sum_all = sum_all.add(atte2, fill_value=0)\n",
      "/tmp/ipykernel_2311809/59325228.py:30: RuntimeWarning: '<' not supported between instances of 'tuple' and 'int', sort order is undefined for incomparable objects.\n",
      "  sum_all = sum_all.add(atte2, fill_value=0)\n",
      "/tmp/ipykernel_2311809/59325228.py:30: RuntimeWarning: '<' not supported between instances of 'tuple' and 'int', sort order is undefined for incomparable objects.\n",
      "  sum_all = sum_all.add(atte2, fill_value=0)\n",
      "/tmp/ipykernel_2311809/59325228.py:30: RuntimeWarning: '<' not supported between instances of 'tuple' and 'int', sort order is undefined for incomparable objects.\n",
      "  sum_all = sum_all.add(atte2, fill_value=0)\n",
      "/tmp/ipykernel_2311809/59325228.py:30: RuntimeWarning: '<' not supported between instances of 'tuple' and 'int', sort order is undefined for incomparable objects.\n",
      "  sum_all = sum_all.add(atte2, fill_value=0)\n",
      "/tmp/ipykernel_2311809/59325228.py:30: RuntimeWarning: '<' not supported between instances of 'tuple' and 'int', sort order is undefined for incomparable objects.\n",
      "  sum_all = sum_all.add(atte2, fill_value=0)\n",
      "/tmp/ipykernel_2311809/59325228.py:30: RuntimeWarning: '<' not supported between instances of 'tuple' and 'int', sort order is undefined for incomparable objects.\n",
      "  sum_all = sum_all.add(atte2, fill_value=0)\n",
      "/tmp/ipykernel_2311809/59325228.py:30: RuntimeWarning: '<' not supported between instances of 'tuple' and 'int', sort order is undefined for incomparable objects.\n",
      "  sum_all = sum_all.add(atte2, fill_value=0)\n",
      "/tmp/ipykernel_2311809/59325228.py:30: RuntimeWarning: '<' not supported between instances of 'tuple' and 'int', sort order is undefined for incomparable objects.\n",
      "  sum_all = sum_all.add(atte2, fill_value=0)\n",
      "/tmp/ipykernel_2311809/59325228.py:30: RuntimeWarning: '<' not supported between instances of 'tuple' and 'int', sort order is undefined for incomparable objects.\n",
      "  sum_all = sum_all.add(atte2, fill_value=0)\n",
      "/tmp/ipykernel_2311809/59325228.py:30: RuntimeWarning: '<' not supported between instances of 'tuple' and 'int', sort order is undefined for incomparable objects.\n",
      "  sum_all = sum_all.add(atte2, fill_value=0)\n",
      "/tmp/ipykernel_2311809/59325228.py:30: RuntimeWarning: '<' not supported between instances of 'tuple' and 'int', sort order is undefined for incomparable objects.\n",
      "  sum_all = sum_all.add(atte2, fill_value=0)\n",
      "/tmp/ipykernel_2311809/59325228.py:30: RuntimeWarning: '<' not supported between instances of 'tuple' and 'int', sort order is undefined for incomparable objects.\n",
      "  sum_all = sum_all.add(atte2, fill_value=0)\n",
      "/tmp/ipykernel_2311809/59325228.py:30: RuntimeWarning: '<' not supported between instances of 'tuple' and 'int', sort order is undefined for incomparable objects.\n",
      "  sum_all = sum_all.add(atte2, fill_value=0)\n",
      "/tmp/ipykernel_2311809/59325228.py:30: RuntimeWarning: '<' not supported between instances of 'tuple' and 'int', sort order is undefined for incomparable objects.\n",
      "  sum_all = sum_all.add(atte2, fill_value=0)\n",
      "/tmp/ipykernel_2311809/59325228.py:30: RuntimeWarning: '<' not supported between instances of 'tuple' and 'int', sort order is undefined for incomparable objects.\n",
      "  sum_all = sum_all.add(atte2, fill_value=0)\n",
      "/tmp/ipykernel_2311809/59325228.py:30: RuntimeWarning: '<' not supported between instances of 'tuple' and 'int', sort order is undefined for incomparable objects.\n",
      "  sum_all = sum_all.add(atte2, fill_value=0)\n",
      "/tmp/ipykernel_2311809/59325228.py:30: RuntimeWarning: '<' not supported between instances of 'tuple' and 'int', sort order is undefined for incomparable objects.\n",
      "  sum_all = sum_all.add(atte2, fill_value=0)\n",
      "/tmp/ipykernel_2311809/59325228.py:30: RuntimeWarning: '<' not supported between instances of 'tuple' and 'int', sort order is undefined for incomparable objects.\n",
      "  sum_all = sum_all.add(atte2, fill_value=0)\n",
      "/tmp/ipykernel_2311809/59325228.py:30: RuntimeWarning: '<' not supported between instances of 'tuple' and 'int', sort order is undefined for incomparable objects.\n",
      "  sum_all = sum_all.add(atte2, fill_value=0)\n",
      "/tmp/ipykernel_2311809/59325228.py:30: RuntimeWarning: '<' not supported between instances of 'tuple' and 'int', sort order is undefined for incomparable objects.\n",
      "  sum_all = sum_all.add(atte2, fill_value=0)\n",
      "/tmp/ipykernel_2311809/59325228.py:30: RuntimeWarning: '<' not supported between instances of 'tuple' and 'int', sort order is undefined for incomparable objects.\n",
      "  sum_all = sum_all.add(atte2, fill_value=0)\n",
      "/tmp/ipykernel_2311809/59325228.py:30: RuntimeWarning: '<' not supported between instances of 'tuple' and 'int', sort order is undefined for incomparable objects.\n",
      "  sum_all = sum_all.add(atte2, fill_value=0)\n",
      "/tmp/ipykernel_2311809/59325228.py:30: RuntimeWarning: '<' not supported between instances of 'tuple' and 'int', sort order is undefined for incomparable objects.\n",
      "  sum_all = sum_all.add(atte2, fill_value=0)\n",
      "/tmp/ipykernel_2311809/59325228.py:30: RuntimeWarning: '<' not supported between instances of 'tuple' and 'int', sort order is undefined for incomparable objects.\n",
      "  sum_all = sum_all.add(atte2, fill_value=0)\n",
      "/tmp/ipykernel_2311809/59325228.py:30: RuntimeWarning: '<' not supported between instances of 'tuple' and 'int', sort order is undefined for incomparable objects.\n",
      "  sum_all = sum_all.add(atte2, fill_value=0)\n",
      "/tmp/ipykernel_2311809/59325228.py:30: RuntimeWarning: '<' not supported between instances of 'tuple' and 'int', sort order is undefined for incomparable objects.\n",
      "  sum_all = sum_all.add(atte2, fill_value=0)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Xg_all = np.concatenate((Xg_train,Xg_test.cpu().detach().numpy()))\n",
    "Xm_all = np.concatenate((Xm_train,Xm_test.cpu().detach().numpy()))\n",
    "att_all = pd.DataFrame()\n",
    "sum_all = pd.DataFrame(np.zeros((dim*dim, 1)))\n",
    "\n",
    "for i in range(y_all.shape[0]):\n",
    "    xg_x = net.task1_FC1_x(torch.tensor(Xg_all[i].reshape(1,-1)).float().cuda())\n",
    "    xg_y = net.task1_FC1_y(torch.tensor(Xg_all[i].reshape(1,-1)).float().cuda())\n",
    "    xm_x = net.task2_FC1_x(torch.tensor(Xm_all[i].reshape(1,-1)).float().cuda())\n",
    "    xm_y = net.task2_FC1_y(torch.tensor(Xm_all[i].reshape(1,-1)).float().cuda())\n",
    "    xg = torch.cat([xg_x.reshape(-1,1,dim),xg_y.reshape(-1,1,dim)], dim=1)\n",
    "    xm = torch.cat([xm_x.reshape(-1,1,dim),xm_y.reshape(-1,1,dim)], dim=1)\n",
    "\n",
    "    norm  = torch.norm(xg, dim=1, keepdim=True)\n",
    "    xg = xg.div(norm)\n",
    "    norm2  = torch.norm(xm, dim=1, keepdim=True)\n",
    "    xm = xm.div(norm2)\n",
    "\n",
    "    energy =  torch.bmm(xg.reshape(-1,2,dim).permute(0,2,1) ,xm.reshape(-1,2,dim)) \n",
    "    att = energy.cpu().detach().numpy().reshape(dim,dim)\n",
    "\n",
    "    ind = np.empty([dim,dim]).astype(str)\n",
    "    for a in range(dim):\n",
    "        for b in range(dim):\n",
    "            st = 'GE module %s, DM module %s' %(a,b)\n",
    "            ind[a,b] = st\n",
    "    atte2 = pd.DataFrame(att.reshape(-1,1),index=ind.reshape(-1,1))\n",
    "    att_all = pd.concat([att_all,atte2],axis=1)\n",
    "    if y_all[i]==1:         #####    change this point\n",
    "        sum_all = sum_all.add(atte2, fill_value=0)\n",
    "sum_all = sum_all[dim*dim:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(GE module 1, DM module 3,)</th>\n",
       "      <td>-79.411677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(GE module 17, DM module 3,)</th>\n",
       "      <td>-79.404943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(GE module 21, DM module 3,)</th>\n",
       "      <td>-79.391105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(GE module 1, DM module 23,)</th>\n",
       "      <td>-79.356561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(GE module 1, DM module 30,)</th>\n",
       "      <td>-79.356451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(GE module 7, DM module 30,)</th>\n",
       "      <td>79.527247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(GE module 7, DM module 23,)</th>\n",
       "      <td>79.527884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(GE module 19, DM module 3,)</th>\n",
       "      <td>79.536056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(GE module 9, DM module 3,)</th>\n",
       "      <td>79.543713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(GE module 7, DM module 3,)</th>\n",
       "      <td>79.574172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1024 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      0\n",
       "(GE module 1, DM module 3,)  -79.411677\n",
       "(GE module 17, DM module 3,) -79.404943\n",
       "(GE module 21, DM module 3,) -79.391105\n",
       "(GE module 1, DM module 23,) -79.356561\n",
       "(GE module 1, DM module 30,) -79.356451\n",
       "...                                 ...\n",
       "(GE module 7, DM module 30,)  79.527247\n",
       "(GE module 7, DM module 23,)  79.527884\n",
       "(GE module 19, DM module 3,)  79.536056\n",
       "(GE module 9, DM module 3,)   79.543713\n",
       "(GE module 7, DM module 3,)   79.574172\n",
       "\n",
       "[1024 rows x 1 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sum_all.sort_values(by=[0]).plot.line()\n",
    "sum_all.sort_values(by=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/user_home/moons/SHOT/toy_GE.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m gene \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/user_home/moons/SHOT/toy_GE.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m    \u001b[38;5;66;03m# for gene name\u001b[39;00m\n\u001b[1;32m      2\u001b[0m me_gene \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/user_home/moons/SHOT/toy_me.csv\u001b[39m\u001b[38;5;124m'\u001b[39m,index_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/Projects/SSCONMF_baselines/2022_MOMA/.moma.env/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/SSCONMF_baselines/2022_MOMA/.moma.env/lib/python3.10/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/Projects/SSCONMF_baselines/2022_MOMA/.moma.env/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/SSCONMF_baselines/2022_MOMA/.moma.env/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/Projects/SSCONMF_baselines/2022_MOMA/.moma.env/lib/python3.10/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/user_home/moons/SHOT/toy_GE.csv'"
     ]
    }
   ],
   "source": [
    "gene = pd.read_csv('/user_home/moons/SHOT/toy_GE.csv',index_col=0)    # for gene name\n",
    "me_gene = pd.read_csv('/user_home/moons/SHOT/toy_me.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importance score of each gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=0  # Important GE module, Ex) (GE module 0, DM module 22,) = 79.999154 \n",
    "sum_gg = pd.DataFrame(index=gene.index) # Importance of each gene\n",
    "for i in range(y_all.shape[0]):\n",
    "    if y_all[i]==1:      #####    change this point\n",
    "        importance = np.matmul(np.transpose(xg[0].cpu().detach().numpy())[k],np.array([net.task1_FC1_x.weight.cpu().detach().numpy()[k],net.task1_FC1_y.weight.\n",
    "                                                                  cpu().detach().numpy()[k]]))\n",
    "\n",
    "        gg = pd.DataFrame(np.transpose([np.multiply(importance,Xg_all[i])]),index=gene.index)\n",
    "        sum_gg = sum_gg.add(gg, fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_gg # Importance of each gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=22  # Important ME module, Ex) (GE module 0, DM module 22,) = 79.999154 \n",
    "sum_mm = pd.DataFrame(index=me_gene.index)\n",
    "for i in range(y_all.shape[0]):\n",
    "    if y_all[i]==1:      #####    change this point\n",
    "        importance = np.matmul(np.transpose(xm[0].cpu().detach().numpy())[k],np.array([net.task2_FC1_x.weight.cpu().detach().numpy()[k],net.task2_FC1_y.weight.\n",
    "                                                                  cpu().detach().numpy()[k]]))\n",
    "        mm = pd.DataFrame(np.transpose([np.multiply(importance,Xm_all[i])]),index=me_gene.index)\n",
    "        sum_mm = sum_mm.add(mm, fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_mm  # Importance of each gene"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization Similarity Score\n",
    "-----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_palette =  dict(zip(np.unique(y_all), \"rbg\"))\n",
    "my_palette[0]  = 'g'\n",
    "my_palette[1]  = 'orange'\n",
    "my_palette[2]  = 'b'\n",
    "my_palette[3]  = 'r'\n",
    "row_colors = pd.DataFrame(y_all)[0].map(my_palette)\n",
    "\n",
    "cluster = sns.clustermap(pd.DataFrame(att_all.values), metric=\"correlation\", method=\"single\", cmap=\"plasma\", col_colors=row_colors,row_cluster=True,dendrogram_ratio=0.2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".moma.env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
