{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# /*==========================================================================================*\\\n",
    "# **                        _           _ _   _     _  _         _                            **\n",
    "# **                       | |__  _   _/ | |_| |__ | || |  _ __ | |__                         **\n",
    "# **                       | '_ \\| | | | | __| '_ \\| || |_| '_ \\| '_ \\                        **\n",
    "# **                       | |_) | |_| | | |_| | | |__   _| | | | | | |                       **\n",
    "# **                       |_.__/ \\__,_|_|\\__|_| |_|  |_| |_| |_|_| |_|                       **\n",
    "# \\*==========================================================================================*/\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "# Author: Bùi Tiến Thành (@bu1th4nh)\n",
    "# Title: playground_classification.ipynb\n",
    "# Date: 2024/10/03 15:27:39\n",
    "# Description: \n",
    "# \n",
    "# (c) bu1th4nh. All rights reserved\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "mlflow.set_tracking_uri(uri=\"http://127.0.0.1:6969\")\n",
    "mlflow.set_experiment(\"SimilarSampleCrossOmicNMF\")\n",
    "\n",
    "\n",
    "\n",
    "# Not fixed gamma\n",
    "# Alpha = 2\n",
    "# run_name = 'ariel-elsa-aurora-20241002-15.12.43'\n",
    "# run_id = 'd4cf242b1a3540d5b2cb91dc52dbd991'\n",
    "\n",
    "# Alpha = 1\n",
    "# run_name = 'ariel-moana-mulan-20241002-23.32.36'\n",
    "# run_id = '1e2f0bbe6ada401aae9d027bcd0fa8b5'\n",
    "\n",
    "# Fixed gamma\n",
    "# run_name = 'merida-mulan-anna-20241003-08.56.41'\n",
    "# run_id = 'abc7d2cfd6d04ab7b48de90d24e8cfc4'\n",
    "\n",
    "# Baseline: NMF Only\n",
    "# run_name = 'rapunzel-rapunzel-ariel-20241006-10.23.03'\n",
    "# run_id = '7f933693ee25409c8fdb90b04a5a26b8'\n",
    "\n",
    "# Baseline: Raw\n",
    "run_name = 'baseline_rawdata'\n",
    "run_id = '62565423ab374538bddded038085c625'\n",
    "\n",
    "\n",
    "\n",
    "ORGL_PATH = '/home/ti514716/Datasets/BreastCancer/processed_crossOmics'\n",
    "RESULT_PATH = '/home/ti514716/Projects/SimilarSampleCrossOmicNMF/results/' + run_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Acquisition & Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = pd.read_parquet(f'{RESULT_PATH}/H.parquet')\n",
    "display(H.head())\n",
    "\n",
    "mRNA = pd.read_parquet(f'{ORGL_PATH}/mRNA.parquet')\n",
    "miRNA = pd.read_parquet(f'{ORGL_PATH}/miRNA.parquet')\n",
    "clinical = pd.read_parquet(f'{ORGL_PATH}/clinical.parquet')\n",
    "\n",
    "display(clinical.head())\n",
    "# display(mRNA.head())\n",
    "# display(miRNA.head())\n",
    "\n",
    "\n",
    "common_samples = list(set(H.index).intersection(clinical.index))\n",
    "print(f'Common samples: {len(common_samples)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = H.loc[common_samples]\n",
    "label = clinical.loc[common_samples, ['ER']]\n",
    "label['ER'] = label['ER'].apply(lambda x: 1 if x == 'Positive' else 0)\n",
    "\n",
    "\n",
    "display(data.head())\n",
    "display(label.head())\n",
    "\n",
    "display(label['ER'].value_counts())\n",
    "\n",
    "positive_samples = list(label[label['ER'] == 1].index)\n",
    "negative_samples = list(label[label['ER'] == 0].index)\n",
    "\n",
    "positive_data = data.loc[positive_samples].copy(deep=True)\n",
    "negative_data = data.loc[negative_samples].copy(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Train-test split for positive and negative samples, ensuring that the positive/negative ratio is maintained\n",
    "X_train_pos, X_test_pos = train_test_split(positive_data, test_size=0.2, random_state=42)\n",
    "X_train_neg, X_test_neg = train_test_split(negative_data, test_size=0.2, random_state=42)\n",
    "Y_train_pos = np.ones(X_train_pos.shape[0])\n",
    "Y_test_pos = np.ones(X_test_pos.shape[0])\n",
    "Y_train_neg = np.zeros(X_train_neg.shape[0])\n",
    "Y_test_neg = np.zeros(X_test_neg.shape[0])\n",
    "\n",
    "train_dataset = pd.concat([X_train_pos, X_train_neg])\n",
    "test_dataset = pd.concat([X_test_pos, X_test_neg])\n",
    "Y_train = np.concatenate([Y_train_pos, Y_train_neg])\n",
    "Y_test = np.concatenate([Y_test_pos, Y_test_neg])\n",
    "\n",
    "train_dataset['ER'] = Y_train\n",
    "test_dataset['ER'] = Y_test\n",
    "\n",
    "\n",
    "# Shuffle\n",
    "train_dataset = train_dataset.sample(frac=1).reset_index(drop=True)\n",
    "test_dataset = test_dataset.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "\n",
    "# Split X-Y\n",
    "X_train = train_dataset.drop(columns=['ER']).values\n",
    "Y_train = train_dataset['ER']\n",
    "X_test = test_dataset.drop(columns=['ER']).values\n",
    "Y_test = test_dataset['ER']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Canonical ML Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVMClassifier(train_data, train_labl):\n",
    "    from sklearn.svm import SVC\n",
    "    return SVC(probability=True, verbose=True).fit(train_data, train_labl)\n",
    "\n",
    "def RandomForestClassifier(train_data, train_labl):\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    return RandomForestClassifier(verbose=True).fit(train_data, train_labl)\n",
    "\n",
    "def LogisticRegressionClassifier(train_data, train_labl):\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    return LogisticRegression(max_iter=1000, verbose=True).fit(train_data, train_labl)\n",
    "\n",
    "def AdaBoostClassifier(train_data, train_labl):\n",
    "    from sklearn.ensemble import AdaBoostClassifier\n",
    "    return AdaBoostClassifier().fit(train_data, train_labl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_methods = [\"AdaBoost\", \"Logistic Regression\", \"Random Forest\", \"SVM\"]\n",
    "model_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification\n",
    "\n",
    "for (j, cls_method) in enumerate(cls_methods):\n",
    "    print(f\"Processing {cls_method}...\")\n",
    "    print(f\"Feature size: {X_train.shape[1]}, Train size: {X_train.shape[0]}, Test size: {X_test.shape[0]}\")\n",
    "\n",
    "    if(cls_method == \"SVM\"):                    cls = SVMClassifier(X_train, Y_train)\n",
    "    elif(cls_method == \"Random Forest\"):         cls = RandomForestClassifier(X_train, Y_train)\n",
    "    elif(cls_method == \"Logistic Regression\"):   cls = LogisticRegressionClassifier(X_train, Y_train)\n",
    "    elif(cls_method == \"AdaBoost\"):             cls = AdaBoostClassifier(X_train, Y_train)\n",
    "    else: raise ValueError(\"Invalid classification method\")\n",
    "\n",
    "    model_dict[cls_method] = cls\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(\n",
    "    2, \n",
    "    2,\n",
    "    figsize=(\n",
    "        20, 7\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "results_AUC = {}\n",
    "with mlflow.start_run(run_id=run_id):\n",
    "    for (j, cls_method) in enumerate(cls_methods):\n",
    "        cls = model_dict[cls_method]\n",
    "        predicted = cls.predict_proba(X_test)[::,1]\n",
    "\n",
    "\n",
    "        fpr, tpr, _ = roc_curve(Y_test, predicted)\n",
    "        auc_value = auc(fpr, tpr)\n",
    "\n",
    "        results_AUC[cls_method] = auc_value\n",
    "        mlflow.log_metric(f\"{cls_method} AUC\", auc_value)\n",
    "                          \n",
    "\n",
    "        # Plot ROC curve\n",
    "        axxx = ax[j // 2, j % 2]\n",
    "        \n",
    "\n",
    "        axxx.plot(list(fpr), list(tpr), label=f\"AUC = {auc_value:.3f}\")\n",
    "        axxx.set_title(f\"{cls_method} | {X_test.shape[1]} features | AUC = {auc_value:.3f}\")\n",
    "\n",
    "    fig.show()\n",
    "    fig.savefig(f\"{RESULT_PATH}/classification_results.pdf\")\n",
    "    mlflow.log_artifact(f\"{RESULT_PATH}/classification_results.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CrossOmics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
