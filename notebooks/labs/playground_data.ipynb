{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# /*==========================================================================================*\\\n",
    "# **                        _           _ _   _     _  _         _                            **\n",
    "# **                       | |__  _   _/ | |_| |__ | || |  _ __ | |__                         **\n",
    "# **                       | '_ \\| | | | | __| '_ \\| || |_| '_ \\| '_ \\                        **\n",
    "# **                       | |_) | |_| | | |_| | | |__   _| | | | | | |                       **\n",
    "# **                       |_.__/ \\__,_|_|\\__|_| |_|  |_| |_| |_|_| |_|                       **\n",
    "# \\*==========================================================================================*/\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "# Author: Bùi Tiến Thành - Tien-Thanh Bui (@bu1th4nh)\n",
    "# Title: playground_data.ipynb\n",
    "# Date: 2024/11/07 14:39:32\n",
    "# Description: \n",
    "# \n",
    "# (c) 2024 bu1th4nh. All rights reserved. \n",
    "# Written with dedication in the University of Central Florida, EPCOT and the Magic Kingdom.\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "\n",
    "from s3fs import S3FileSystem\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score, recall_score, f1_score, matthews_corrcoef, roc_auc_score, average_precision_score\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "key = 'bu1th4nh'\n",
    "secret = 'ariel.anna.elsa'\n",
    "endpoint_url = 'http://localhost:9000'\n",
    "\n",
    "s3 = S3FileSystem(\n",
    "    anon=False, \n",
    "    endpoint_url=endpoint_url,\n",
    "    key=key,\n",
    "    secret=secret,\n",
    "    use_ssl=False\n",
    ")\n",
    "storage_options = {\n",
    "    'key': key,\n",
    "    'secret': secret,\n",
    "    'endpoint_url': endpoint_url,\n",
    "}\n",
    "storage_option = storage_options\n",
    "DATA_PATH = 's3://datasets/LungCancer/processed_3_omics_mRNA_miRNA_methDNA'\n",
    "SA_TARG_PATH = f's3://datasets/LungCancer/survivalanalysis_testdata_3_omics_mRNA_miRNA_methDNA'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_one_target(H, testdata, methods_list, target):\n",
    "    # Prepping the data and result\n",
    "\n",
    "    metrics = ['pred', 'prob', 'ACC', 'REC', 'F1', 'MCC', 'AUROC', 'AUPRC']\n",
    "    results = {\n",
    "        method: pd.DataFrame(index = testdata.index, columns = metrics) \n",
    "        for method in methods_list\n",
    "    }\n",
    "\n",
    "    # Iterate through each test\n",
    "    for test_id in tqdm(testdata.index, desc=f\"Evaluating target {target} on testdata\"):\n",
    "        # Get sample IDs\n",
    "        train_sample_ids = testdata.loc[test_id, f'train_sample_ids']\n",
    "        train_gnd_truth = testdata.loc[test_id, f'train_ground_truth']\n",
    "        test_sample_ids = testdata.loc[test_id, f'test_sample_ids']\n",
    "        test_gnd_truth = testdata.loc[test_id, f'test_ground_truth']\n",
    "\n",
    "        # Get train test X/Y\n",
    "        X_train = H.loc[train_sample_ids].values\n",
    "        Y_train = np.array(train_gnd_truth)\n",
    "        X_test = H.loc[test_sample_ids].values\n",
    "        Y_test = np.array(test_gnd_truth)\n",
    "\n",
    "        # Evaluate each method\n",
    "        for cls_method in methods_list:\n",
    "            if(cls_method == \"SVM\"):                    cls = SVC(probability=True, verbose=False)\n",
    "            elif(cls_method == \"Random Forest\"):        cls = RandomForestClassifier(verbose=False)\n",
    "            elif(cls_method == \"Logistic Regression\"):  cls = LogisticRegression(max_iter=1000, verbose=False)\n",
    "            elif(cls_method == \"AdaBoost\"):             cls = AdaBoostClassifier()\n",
    "\n",
    "            # Fit & predict the model\n",
    "            cls.fit(X_train, Y_train)\n",
    "            pred = cls.predict(X_test)\n",
    "            prob = cls.predict_proba(X_test)[::,1]\n",
    "\n",
    "            # Metrics\n",
    "            ACC = accuracy_score(Y_test, pred)\n",
    "            REC = recall_score(Y_test, pred)\n",
    "            F1 = f1_score(Y_test, pred)\n",
    "            MCC = matthews_corrcoef(Y_test, pred)\n",
    "            AUROC = roc_auc_score(Y_test, prob)\n",
    "            AUPRC = average_precision_score(Y_test, prob)\n",
    "\n",
    "            # Store the result\n",
    "            results[cls_method].at[test_id, 'pred'] = pred\n",
    "            results[cls_method].at[test_id, 'prob'] = prob\n",
    "            results[cls_method].at[test_id, 'ACC'] = ACC\n",
    "            results[cls_method].at[test_id, 'REC'] = REC\n",
    "            results[cls_method].at[test_id, 'F1'] = F1\n",
    "            results[cls_method].at[test_id, 'MCC'] = MCC\n",
    "            results[cls_method].at[test_id, 'AUROC'] = AUROC\n",
    "            results[cls_method].at[test_id, 'AUPRC'] = AUPRC\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "H = pd.read_parquet('s3://results/SimilarSampleCrossOmicNMF/brca/k-10-alpha-0-beta-0.01-gamma-overridden/H.parquet', storage_options=storage_option)\n",
    "test_data = pd.read_parquet('s3://datasets/BreastCancer/clinical_testdata/ER.parquet', storage_options=storage_option)\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score, recall_score, f1_score, matthews_corrcoef, roc_auc_score, average_precision_score, precision_score\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "train_sample_ids = test_data.loc['Test000', 'train_sample_ids']\n",
    "train_gnd_truth = test_data.loc['Test000', 'train_ground_truth']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ariel = cross_validate(\n",
    "    estimator=SVC(),\n",
    "    X=H.loc[train_sample_ids].values,\n",
    "    y=train_gnd_truth,\n",
    "    return_train_score=False,\n",
    "    # return_estimator=True,\n",
    "    n_jobs=-1,\n",
    "    scoring={\n",
    "        'ACC': 'accuracy',\n",
    "        'PRE': 'precision',\n",
    "        'REC': 'recall',\n",
    "        'F1': 'f1',\n",
    "        'MCC': 'matthews_corrcoef',\n",
    "        'AUROC': 'roc_auc',\n",
    "        'AUPRC': 'average_precision',\n",
    "    }\n",
    ")\n",
    "Ariel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "bipart_data = pd.read_parquet(f'{DATA_PATH}/bipart.parquet', storage_options=storage_options)\n",
    "methDNA = pd.read_parquet(f'{DATA_PATH}/methDNA.parquet', storage_options=storage_options)\n",
    "miRNA = pd.read_parquet(f'{DATA_PATH}/miRNA.parquet', storage_options=storage_options)\n",
    "mRNA = pd.read_parquet(f'{DATA_PATH}/mRNA.parquet', storage_options=storage_options)\n",
    "\n",
    "features_list = [mRNA.index.to_list(), miRNA.index.to_list(), methDNA.index.to_list()]   \n",
    "omics_data = [mRNA, miRNA, methDNA]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preloading target data: 100%|██████████| 2/2 [00:00<00:00, 46.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Disease Free Status', 'Disease Free (Months)'], dtype='object')\n",
      "Index(['Overall Survival Status', 'Overall Survival (Months)'], dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "# Obtain survival analysis targets\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "# logging.info(f\"Retrieving survival analysis targets from {SA_TARG_PATH}\")\n",
    "surv_targets_data = {}\n",
    "surv_target_folder = [f's3://{a}' for a in s3.ls(SA_TARG_PATH)]\n",
    "for tar in tqdm(surv_target_folder, desc='Preloading target data'):\n",
    "    target_id = str(tar.split('/')[-1]).split('.')[0]\n",
    "    surv_targets_data[target_id] = pd.read_parquet(tar, storage_options=storage_options)\n",
    "    print(surv_targets_data[target_id].columns)\n",
    "\n",
    "survival = surv_targets_data[list(surv_targets_data.keys())[1]]\n",
    "H_original_data = pd.concat(omics_data, axis=0)\n",
    "H_original_data = H_original_data[list(set(H_original_data.columns).intersection(set(survival.index)))]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CrossOmics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
