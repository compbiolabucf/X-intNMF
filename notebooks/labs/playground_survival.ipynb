{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# /*==========================================================================================*\\\n",
    "# **                        _           _ _   _     _  _         _                            **\n",
    "# **                       | |__  _   _/ | |_| |__ | || |  _ __ | |__                         **\n",
    "# **                       | '_ \\| | | | | __| '_ \\| || |_| '_ \\| '_ \\                        **\n",
    "# **                       | |_) | |_| | | |_| | | |__   _| | | | | | |                       **\n",
    "# **                       |_.__/ \\__,_|_|\\__|_| |_|  |_| |_| |_|_| |_|                       **\n",
    "# \\*==========================================================================================*/\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "# Author: Bùi Tiến Thành - Tien-Thanh Bui (@bu1th4nh)\n",
    "# Title: playground_survival.ipynb\n",
    "# Date: 2025/02/05 17:30:55\n",
    "# Description: \n",
    "# \n",
    "# (c) 2025 bu1th4nh. All rights reserved. \n",
    "# Written with dedication in the University of Central Florida, EPCOT and the Magic Kingdom.\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from typing import List, Dict, Any, Tuple, Union, Literal\n",
    "import warnings \n",
    "\n",
    "from s3fs import S3FileSystem\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "from sklearn import set_config\n",
    "from sklearn.model_selection import GridSearchCV, KFold, train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.exceptions import FitFailedWarning\n",
    "\n",
    "from sksurv.linear_model import CoxnetSurvivalAnalysis\n",
    "import lifelines\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "warnings.simplefilter(\"ignore\", FitFailedWarning)\n",
    "\n",
    "\n",
    "\n",
    "key = 'bu1th4nh'\n",
    "secret = 'ariel.anna.elsa'\n",
    "endpoint_url = 'http://localhost:9000'\n",
    "\n",
    "s3 = S3FileSystem(\n",
    "    anon=False, \n",
    "    endpoint_url=endpoint_url,\n",
    "    key=key,\n",
    "    secret=secret,\n",
    "    use_ssl=False\n",
    ")\n",
    "storage_options = {\n",
    "    'key': key,\n",
    "    'secret': secret,\n",
    "    'endpoint_url': endpoint_url,\n",
    "}\n",
    "\n",
    "DATA_PATH = 's3://datasets/BreastCancer'\n",
    "RESU_PATH = 's3://results/SimilarSampleCrossOmicNMF_3Omics/brca'\n",
    "\n",
    "RESU_PATH = 's3://results/SimilarSampleCrossOmicNMF/brca'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "survival = pd.read_parquet(f'{DATA_PATH}/processed_3_omics_mRNA_miRNA_methDNA/survival.parquet', storage_options=storage_options)\n",
    "H = pd.read_parquet(f'{RESU_PATH}/k-100-alpha-100-beta-10-gamma-overridden/H.parquet', storage_options=storage_options)\n",
    "\n",
    "\n",
    "survival = pd.read_parquet(f'{DATA_PATH}/processed_2_omics_mRNA_miRNA/survival.parquet', storage_options=storage_options)\n",
    "H = pd.read_parquet(f'{RESU_PATH}/k-10-alpha-1000-beta-1-gamma-overridden/H.parquet', storage_options=storage_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survival['Overall Survival Status'] = survival['Overall Survival Status'].replace({'0:LIVING': False, '1:DECEASED': True}).astype(bool)\n",
    "survival['Disease Free Status'] = survival['Disease Free Status'].replace({'0:DiseaseFree': False, '1:Recurred/Progressed': True}).astype(bool)\n",
    "survival.dropna(inplace=True)\n",
    "\n",
    "display(survival.head())\n",
    "display(H.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survival = survival[survival['Disease Free (Months)'] > 0]\n",
    "\n",
    "\n",
    "print(survival.shape)\n",
    "print(H.shape)\n",
    "\n",
    "print(len(common_sample_id := list(set(H.index) & set(survival.index))))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "warnings.simplefilter(\"ignore\", FitFailedWarning)\n",
    "\n",
    "while True:\n",
    "    warnings.simplefilter(\"ignore\", UserWarning)\n",
    "    train_sample_ids, test_sample_ids = train_test_split(common_sample_id, test_size=0.2)\n",
    "    print(len(train_sample_ids), len(test_sample_ids))\n",
    "\n",
    "    X_train = H.loc[train_sample_ids, :].values\n",
    "    X_test = H.loc[test_sample_ids, :].values\n",
    "\n",
    "    Y_train = (\n",
    "        survival\n",
    "        .loc[train_sample_ids, ['Overall Survival Status', 'Overall Survival (Months)']]\n",
    "        .to_records(index=False)\n",
    "    )\n",
    "\n",
    "    # print(Y_train)\n",
    "    # print(X_train)\n",
    "\n",
    "    # Get possible alphas\n",
    "    coxnet_pipe = make_pipeline(StandardScaler(), CoxnetSurvivalAnalysis(l1_ratio=0.5, alpha_min_ratio=0.01, max_iter=100))\n",
    "    coxnet_pipe.fit(X_train, Y_train)\n",
    "    estimated_alphas = coxnet_pipe.named_steps[\"coxnetsurvivalanalysis\"].alphas_\n",
    "\n",
    "    # 5-fold CV to find optimal alpha\n",
    "    cv = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "    gcv = GridSearchCV(\n",
    "        make_pipeline(StandardScaler(), CoxnetSurvivalAnalysis(l1_ratio=0.5)),\n",
    "        param_grid={\"coxnetsurvivalanalysis__alphas\": [[v] for v in estimated_alphas]},\n",
    "        cv=cv,\n",
    "        error_score=0.5,\n",
    "        n_jobs=3,\n",
    "    ).fit(X_train, Y_train)\n",
    "    print(gcv.best_estimator_.named_steps['coxnetsurvivalanalysis'].alphas[0])\n",
    "    alpha = gcv.best_estimator_.named_steps['coxnetsurvivalanalysis'].alphas[0]\n",
    "\n",
    "    # Fit final model\n",
    "    coxnet_pipe = make_pipeline(StandardScaler(), CoxnetSurvivalAnalysis(l1_ratio=0.5, alphas=[alpha]))\n",
    "    coxnet_pipe.fit(X_train, Y_train)\n",
    "\n",
    "\n",
    "    # Get prognostic index\n",
    "    Y_pred = pd.Series(\n",
    "        coxnet_pipe.predict(X_test),\n",
    "        index = test_sample_ids,\n",
    "    )\n",
    "    prognostic_index = Y_pred.median()\n",
    "\n",
    "\n",
    "    # Split test set into high/low risk groups\n",
    "    high_risk_ids = Y_pred[Y_pred > prognostic_index].index\n",
    "    low_risk_ids = Y_pred[Y_pred <= prognostic_index].index\n",
    "    print(len(high_risk_ids), len(low_risk_ids))\n",
    "\n",
    "\n",
    "    # Kaplan-Meier estimator\n",
    "    high_risk_time_exit = survival.loc[high_risk_ids, 'Disease Free (Months)'].values\n",
    "    high_risk_event_observed = survival.loc[high_risk_ids, 'Disease Free Status'].values\n",
    "    kmf_high = lifelines.KaplanMeierFitter()\n",
    "    kmf_high.fit(\n",
    "        high_risk_time_exit, \n",
    "        high_risk_event_observed,\n",
    "        label='High-Risk Group'\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    low_risk_time_exit = survival.loc[low_risk_ids, 'Disease Free (Months)'].values\n",
    "    low_risk_event_observed = survival.loc[low_risk_ids, 'Disease Free Status'].values\n",
    "    kmf_low = lifelines.KaplanMeierFitter()\n",
    "    kmf_low.fit(\n",
    "        low_risk_time_exit, \n",
    "        low_risk_event_observed,\n",
    "        label='Low-Risk Group'\n",
    "    )\n",
    "    # kmf_low.plot(show_censors = True)\n",
    "    # kmf_high.plot(show_censors = True)\n",
    "\n",
    "\n",
    "    # P-value\n",
    "    from lifelines.statistics import logrank_test\n",
    "    results = logrank_test(\n",
    "        low_risk_time_exit, \n",
    "        high_risk_time_exit, \n",
    "        event_observed_A=low_risk_event_observed, \n",
    "        event_observed_B=high_risk_event_observed\n",
    "    )\n",
    "    # print(f'P-value: {results.p_value}')\n",
    "\n",
    "    # draw p-value into plot\n",
    "    # import matplotlib.pyplot as plt\n",
    "    # plt.text(0.6, 0.2, f'P-value: {results.p_value:.4f}', transform=plt.gca().transAxes)\n",
    "    # plt.show()\n",
    "\n",
    "\n",
    "    # C-index\n",
    "    from sksurv.metrics import concordance_index_censored\n",
    "    c_index = concordance_index_censored(\n",
    "        survival.loc[test_sample_ids, 'Disease Free Status'].values, \n",
    "        survival.loc[test_sample_ids, 'Disease Free (Months)'].values, \n",
    "        Y_pred\n",
    "    )\n",
    "\n",
    "    # print(f'Concordance index: {c_index[0]}')\n",
    "\n",
    "    if (results.p_value < 0.01): \n",
    "        print('Found!')\n",
    "        kmf_low.plot(show_censors = True)\n",
    "        kmf_high.plot(show_censors = True)\n",
    "        # draw p-value into plot\n",
    "        import matplotlib.pyplot as plt\n",
    "        plt.text(0.6, 0.2, f'P-value: {results.p_value:.4f}', transform=plt.gca().transAxes)\n",
    "        plt.show()\n",
    "        raise ValueError('Done.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CrossOmics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
