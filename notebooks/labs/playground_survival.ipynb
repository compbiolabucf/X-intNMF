{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# /*==========================================================================================*\\\n",
    "# **                        _           _ _   _     _  _         _                            **\n",
    "# **                       | |__  _   _/ | |_| |__ | || |  _ __ | |__                         **\n",
    "# **                       | '_ \\| | | | | __| '_ \\| || |_| '_ \\| '_ \\                        **\n",
    "# **                       | |_) | |_| | | |_| | | |__   _| | | | | | |                       **\n",
    "# **                       |_.__/ \\__,_|_|\\__|_| |_|  |_| |_| |_|_| |_|                       **\n",
    "# \\*==========================================================================================*/\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "# Author: Bùi Tiến Thành - Tien-Thanh Bui (@bu1th4nh)\n",
    "# Title: playground_survival.ipynb\n",
    "# Date: 2025/02/05 17:30:55\n",
    "# Description: \n",
    "# \n",
    "# (c) 2025 bu1th4nh. All rights reserved. \n",
    "# Written with dedication in the University of Central Florida, EPCOT and the Magic Kingdom.\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "\n",
    "import os\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\") \n",
    "os.environ[\"PYTHONWARNINGS\"] = \"ignore::UserWarning\"\n",
    "\n",
    "\n",
    "\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from typing import List, Dict, Any, Tuple, Union, Literal\n",
    "\n",
    "import pymongo\n",
    "from s3fs import S3FileSystem\n",
    "\n",
    "from sklearn import set_config\n",
    "from sklearn.model_selection import GridSearchCV, KFold, train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.exceptions import FitFailedWarning\n",
    "\n",
    "from sksurv.linear_model import CoxnetSurvivalAnalysis\n",
    "import lifelines\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "key = 'bu1th4nh'\n",
    "secret = 'ariel.anna.elsa'\n",
    "endpoint_url = 'http://localhost:9000'\n",
    "\n",
    "s3 = S3FileSystem(\n",
    "    anon=False, \n",
    "    endpoint_url=endpoint_url,\n",
    "    key=key,\n",
    "    secret=secret,\n",
    "    use_ssl=False\n",
    ")\n",
    "storage_options = {\n",
    "    'key': key,\n",
    "    'secret': secret,\n",
    "    'endpoint_url': endpoint_url,\n",
    "}\n",
    "\n",
    "\n",
    "mongo = pymongo.MongoClient(\n",
    "    host='mongodb://localhost',\n",
    "    port=27017,\n",
    "    username='bu1th4nh',\n",
    "    password='ariel.anna.elsa',\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_selection(omics_mode, disease):\n",
    "    base_data_path = 's3://datasets'\n",
    "    base_result_path = 's3://results'\n",
    "    if omics_mode == \"3omics\":\n",
    "        mongo_db_name           = 'SimilarSampleCrossOmicNMF_3Omics'\n",
    "        base_result_path        = f'{base_result_path}/SimilarSampleCrossOmicNMF_3Omics'\n",
    "        omic_folder             = 'processed_3_omics_mRNA_miRNA_methDNA'\n",
    "        cls_target_folder       = 'clinical_testdata_3_omics_mRNA_miRNA_methDNA'\n",
    "        surv_target_folder      = 'survivalanalysis_testdata_3_omics_mRNA_miRNA_methDNA'\n",
    "        experiment_addon_ext    = '_3Omics'\n",
    "    elif omics_mode == \"2omics\":\n",
    "        mongo_db_name           = 'SimilarSampleCrossOmicNMF'\n",
    "        base_result_path        = f'{base_result_path}/SimilarSampleCrossOmicNMF'\n",
    "        omic_folder             = 'processed_2_omics_mRNA_miRNA'\n",
    "        cls_target_folder       = 'clinical_testdata_2_omics_mRNA_miRNA'\n",
    "        surv_target_folder      = 'survivalanalysis_testdata_2_omics_mRNA_miRNA'\n",
    "        experiment_addon_ext    = ''\n",
    "\n",
    "\n",
    "    # Disease\n",
    "    if disease == \"brca\":\n",
    "        dataset_id              = 'BRCA'\n",
    "        mongo_collection        = 'BRCA'\n",
    "        disease_data_folder     = 'BreastCancer'\n",
    "        disease_result_folder   = 'brca'\n",
    "        experiment_name         = f'SimilarSampleCrossOmicNMFv3_BRCA{experiment_addon_ext}'\n",
    "    elif disease == \"luad\":\n",
    "        dataset_id              = 'LUAD'\n",
    "        mongo_collection        = 'LUAD'\n",
    "        disease_data_folder     = 'LungCancer'\n",
    "        disease_result_folder   = 'luad'\n",
    "        experiment_name         = f'SimilarSampleCrossOmicNMFv3_LUAD{experiment_addon_ext}'\n",
    "    elif disease == \"ov\":\n",
    "        dataset_id              = 'OV'\n",
    "        mongo_collection        = 'OV'\n",
    "        disease_data_folder     = 'OvarianCancer'\n",
    "        disease_result_folder   = 'ov'\n",
    "        experiment_name         = f'SimilarSampleCrossOmicNMFv3_OV{experiment_addon_ext}'\n",
    "    elif disease == \"test\":\n",
    "        dataset_id              = 'test'\n",
    "        mongo_collection        = 'TEST'\n",
    "        disease_data_folder     = 'BreastCancer'\n",
    "        disease_result_folder   = 'test'\n",
    "        experiment_name         = 'test_experiment'\n",
    "\n",
    "    \n",
    "    # Aggregate\n",
    "    SA_TARG_PATH = f'{base_data_path}/{disease_data_folder}/{surv_target_folder}'\n",
    "    DATA_PATH = f'{base_data_path}/{disease_data_folder}/{omic_folder}'\n",
    "    RESULT_PRE_PATH = f'{base_result_path}/{disease_result_folder}'\n",
    "\n",
    "\n",
    "    return mongo_db_name, dataset_id, DATA_PATH, RESULT_PRE_PATH, SA_TARG_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preloading target data: 100%|██████████| 2/2 [00:00<00:00, 14.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Disease Free Status', 'Disease Free (Months)'], dtype='object')\n",
      "Index(['Overall Survival Status', 'Overall Survival (Months)'], dtype='object')\n",
      "SA for BRCA with ER, config k-100-alpha-0.01-beta-0.01-gamma-overridden and diseasefree, attempt 1\n",
      "Error\n",
      "SA for BRCA with ER, config k-100-alpha-0.01-beta-0.01-gamma-overridden and diseasefree, attempt 2\n"
     ]
    }
   ],
   "source": [
    "from downstream.survival import surv_analysis\n",
    "\n",
    "for omics_mode in ['2omics', '3omics']:\n",
    "    for disease in ['brca', 'luad', 'ov']:\n",
    "        mongo_db_name, dataset_id, DATA_PATH, RESULT_PRE_PATH, SA_TARG_PATH = data_selection(omics_mode, disease)\n",
    "\n",
    "        # Obtain db and collection\n",
    "        mongo_db = mongo[mongo_db_name]\n",
    "        hparams_runs = mongo_db['HPARAMS_OPTS']\n",
    "        surv_result = mongo_db['SURVIVAL_ANALYSIS']\n",
    "\n",
    "\n",
    "        # Obtain survival analysis targets\n",
    "        surv_targets_data = {}\n",
    "        surv_target_folder = [f's3://{a}' for a in s3.ls(SA_TARG_PATH)]\n",
    "        for tar in tqdm(surv_target_folder, desc='Preloading target data'):\n",
    "            target_id = str(tar.split('/')[-1]).split('.')[0]\n",
    "            # print(target_id, tar)\n",
    "            try:\n",
    "                surv_targets_data[target_id] = pd.read_parquet(tar, storage_options=storage_options)\n",
    "                print(surv_targets_data[target_id].columns)\n",
    "\n",
    "            except FileNotFoundError:\n",
    "                logging.error(f\"Target {tar} not found. Skipping...\")   \n",
    "\n",
    "\n",
    "\n",
    "        # Get target id for each disease => find the best hparams for each target\n",
    "        classification_target_ids_for_disease = hparams_runs.find(\n",
    "            {'dataset': dataset_id},\n",
    "        ).distinct('target_id')\n",
    "        \n",
    "\n",
    "\n",
    "        # Get the best hparams for each target and run SA\n",
    "        for classification_target_id in classification_target_ids_for_disease:\n",
    "            Ariel = (\n",
    "                pd.DataFrame.from_records(\n",
    "                    hparams_runs\n",
    "                    .find(\n",
    "                        {\n",
    "                            \"dataset\": dataset_id,\n",
    "                            \"target_id\": classification_target_id,\n",
    "                        },\n",
    "                        {\n",
    "                            \"_id\": 0,\n",
    "                            \"test_id\": 1,   \n",
    "                            \"config\": 1,\n",
    "                            \"AUROC\": 1,\n",
    "                        }\n",
    "                    ).to_list()\n",
    "                )[['config', 'AUROC']]\n",
    "                .groupby('config')\n",
    "                .mean()\n",
    "            )\n",
    "            best_cfg = Ariel.index[np.argmax(Ariel.values)]\n",
    "            H = pd.read_parquet(f'{RESULT_PRE_PATH}/{best_cfg}/H.parquet', storage_options=storage_options)\n",
    "\n",
    "\n",
    "            # Get all survival analysis targets\n",
    "            for surv_target_id in surv_targets_data.keys():\n",
    "                survival = surv_targets_data[surv_target_id]\n",
    "                train_sample_ids, test_sample_ids = train_test_split(survival.index, test_size=0.2)\n",
    "\n",
    "                if surv_target_id == 'survival': \n",
    "                    event_label = 'Overall Survival Status'\n",
    "                    time_label = 'Overall Survival (Months)'\n",
    "                else:\n",
    "                    event_label = 'Disease Free Status'\n",
    "                    time_label = 'Disease Free (Months)'\n",
    "\n",
    "                attempt = 0\n",
    "                while True:\n",
    "                    attempt += 1\n",
    "                    print(f'SA for {dataset_id} with {classification_target_id}, config {best_cfg} and {surv_target_id}, attempt {attempt}')\n",
    "\n",
    "                    try:\n",
    "                        surv_result = surv_analysis(\n",
    "                            H,\n",
    "                            train_sample_ids,\n",
    "                            survival.loc[train_sample_ids],\n",
    "                            test_sample_ids,\n",
    "                            survival.loc[test_sample_ids],\n",
    "                            event_label,\n",
    "                            time_label,\n",
    "                        )\n",
    "\n",
    "\n",
    "                        if surv_result['p_value'] < 0.05:\n",
    "                            print(surv_result)\n",
    "                            break\n",
    "                        else:\n",
    "                            print('p-value > 0.05:', surv_result['p_value'])\n",
    "                    except:\n",
    "                        print('Error')\n",
    "                        continue\n",
    "\n",
    "            \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(Ariel['results'])\n",
    "\n",
    "X_low = Ariel['kaplan_meier_curve']['X_low']\n",
    "Y_low = Ariel['kaplan_meier_curve']['Y_low']\n",
    "X_high = Ariel['kaplan_meier_curve']['X_high']\n",
    "Y_high = Ariel['kaplan_meier_curve']['Y_high']\n",
    "censor_low = Ariel['kaplan_meier_curve']['censor_low']\n",
    "censor_high = Ariel['kaplan_meier_curve']['censor_high']\n",
    "censor_low_pred = Ariel['kaplan_meier_curve']['censor_low_pred']\n",
    "censor_high_pred = Ariel['kaplan_meier_curve']['censor_high_pred']\n",
    "low_risk_ids = Ariel['test_low_risk_ids']\n",
    "high_risk_ids = Ariel['test_high_risk_ids']\n",
    "p_value = Ariel['p_value']\n",
    "\n",
    "\n",
    "# Plot survival functions\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.step(X_low, Y_low, where=\"post\", label=f\"low-risk ({len(low_risk_ids)})\", color=\"blue\", linestyle=\"--\")\n",
    "plt.step(X_high, Y_high, where=\"post\", label=f\"high-risk ({len(high_risk_ids)})\", color=\"red\", linestyle=\"-\")\n",
    "\n",
    "# Plot censor points\n",
    "plt.scatter(censor_high, censor_high_pred, marker='+', color='black')\n",
    "plt.scatter(censor_low, censor_low_pred, marker='+', color='black')\n",
    "\n",
    "# Add labels and legend\n",
    "plt.title(\"Kaplan-Meier Curves\")\n",
    "plt.xlabel(\"Time (Months)\")\n",
    "plt.ylabel(\"Survival Probability\")\n",
    "plt.legend()\n",
    "# plt.grid(True)\n",
    "\n",
    "# Add p-value in a box on the bottom left of the plot\n",
    "plt.text(0.03, 0.05, f'p-value: {p_value:.4f}', transform=plt.gca().transAxes, bbox=dict(facecolor='white', alpha=0.5, edgecolor='black'))\n",
    "\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CrossOmics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
