{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# /*==========================================================================================*\\\n",
    "# **                        _           _ _   _     _  _         _                            **\n",
    "# **                       | |__  _   _/ | |_| |__ | || |  _ __ | |__                         **\n",
    "# **                       | '_ \\| | | | | __| '_ \\| || |_| '_ \\| '_ \\                        **\n",
    "# **                       | |_) | |_| | | |_| | | |__   _| | | | | | |                       **\n",
    "# **                       |_.__/ \\__,_|_|\\__|_| |_|  |_| |_| |_|_| |_|                       **\n",
    "# \\*==========================================================================================*/\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "# Author: Bùi Tiến Thành - Tien-Thanh Bui (@bu1th4nh)\n",
    "# Title: playground_data.ipynb\n",
    "# Date: 2024/11/07 14:39:32\n",
    "# Description: \n",
    "# \n",
    "# (c) 2024 bu1th4nh. All rights reserved. \n",
    "# Written with dedication in the University of Central Florida, EPCOT and the Magic Kingdom.\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "\n",
    "from s3fs import S3FileSystem\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score, recall_score, f1_score, matthews_corrcoef, roc_auc_score, average_precision_score\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "key = 'bu1th4nh'\n",
    "secret = 'ariel.anna.elsa'\n",
    "endpoint_url = 'http://localhost:9000'\n",
    "\n",
    "s3 = S3FileSystem(\n",
    "    anon=False, \n",
    "    endpoint_url=endpoint_url,\n",
    "    key=key,\n",
    "    secret=secret,\n",
    "    use_ssl=False\n",
    ")\n",
    "storage_option = {\n",
    "    'key': key,\n",
    "    'secret': secret,\n",
    "    'endpoint_url': endpoint_url,\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_one_target(H, testdata, methods_list, target):\n",
    "    # Prepping the data and result\n",
    "\n",
    "    metrics = ['pred', 'prob', 'ACC', 'REC', 'F1', 'MCC', 'AUROC', 'AUPRC']\n",
    "    results = {\n",
    "        method: pd.DataFrame(index = testdata.index, columns = metrics) \n",
    "        for method in methods_list\n",
    "    }\n",
    "\n",
    "    # Iterate through each test\n",
    "    for test_id in tqdm(testdata.index, desc=f\"Evaluating target {target} on testdata\"):\n",
    "        # Get sample IDs\n",
    "        train_sample_ids = testdata.loc[test_id, f'train_sample_ids']\n",
    "        train_gnd_truth = testdata.loc[test_id, f'train_ground_truth']\n",
    "        test_sample_ids = testdata.loc[test_id, f'test_sample_ids']\n",
    "        test_gnd_truth = testdata.loc[test_id, f'test_ground_truth']\n",
    "\n",
    "        # Get train test X/Y\n",
    "        X_train = H.loc[train_sample_ids].values\n",
    "        Y_train = np.array(train_gnd_truth)\n",
    "        X_test = H.loc[test_sample_ids].values\n",
    "        Y_test = np.array(test_gnd_truth)\n",
    "\n",
    "        # Evaluate each method\n",
    "        for cls_method in methods_list:\n",
    "            if(cls_method == \"SVM\"):                    cls = SVC(probability=True, verbose=False)\n",
    "            elif(cls_method == \"Random Forest\"):        cls = RandomForestClassifier(verbose=False)\n",
    "            elif(cls_method == \"Logistic Regression\"):  cls = LogisticRegression(max_iter=1000, verbose=False)\n",
    "            elif(cls_method == \"AdaBoost\"):             cls = AdaBoostClassifier()\n",
    "\n",
    "            # Fit & predict the model\n",
    "            cls.fit(X_train, Y_train)\n",
    "            pred = cls.predict(X_test)\n",
    "            prob = cls.predict_proba(X_test)[::,1]\n",
    "\n",
    "            # Metrics\n",
    "            ACC = accuracy_score(Y_test, pred)\n",
    "            REC = recall_score(Y_test, pred)\n",
    "            F1 = f1_score(Y_test, pred)\n",
    "            MCC = matthews_corrcoef(Y_test, pred)\n",
    "            AUROC = roc_auc_score(Y_test, prob)\n",
    "            AUPRC = average_precision_score(Y_test, prob)\n",
    "\n",
    "            # Store the result\n",
    "            results[cls_method].at[test_id, 'pred'] = pred\n",
    "            results[cls_method].at[test_id, 'prob'] = prob\n",
    "            results[cls_method].at[test_id, 'ACC'] = ACC\n",
    "            results[cls_method].at[test_id, 'REC'] = REC\n",
    "            results[cls_method].at[test_id, 'F1'] = F1\n",
    "            results[cls_method].at[test_id, 'MCC'] = MCC\n",
    "            results[cls_method].at[test_id, 'AUROC'] = AUROC\n",
    "            results[cls_method].at[test_id, 'AUPRC'] = AUPRC\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "H = pd.read_parquet('s3://results/SimilarSampleCrossOmicNMF/brca/k-10-alpha-0-beta-0.01-gamma-overridden/H.parquet', storage_options=storage_option)\n",
    "test_data = pd.read_parquet('s3://datasets/BreastCancer/clinical_testdata/ER.parquet', storage_options=storage_option)\n",
    "\n",
    "# Evaluate\n",
    "result_pack = evaluate_one_target(H, testdata = test_data, methods_list = [\"Logistic Regression\", \"Random Forest\"], target = 'ER')\n",
    "\n",
    "# Load to staging package\n",
    "data_pack = {\n",
    "    'run_id': '1',\n",
    "    'target_id': 'ER',\n",
    "    'summary': {}\n",
    "}\n",
    "for method in result_pack.keys():\n",
    "    data_pack[method] = result_pack[method].to_dict(orient='index')\n",
    "\n",
    "    for metric in result_pack[method].columns:\n",
    "        if str(metric).isupper():\n",
    "            # Assume all metrics are upper case-noted columns\n",
    "            data_pack['summary'][f'{method} Mean {metric}'] = np.mean(result_pack[method][metric].values)\n",
    "            data_pack['summary'][f'{method} Median {metric}'] = np.median(result_pack[method][metric].values)\n",
    "            data_pack['summary'][f'{method} Std {metric}'] = np.std(result_pack[method][metric].values)\n",
    "            data_pack['summary'][f'{method} Max {metric}'] = np.max(result_pack[method][metric].values)\n",
    "            data_pack['summary'][f'{method} Min {metric}'] = np.min(result_pack[method][metric].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_pack[\"Random Forest\"].to_dict(orient='index', index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CrossOmics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
